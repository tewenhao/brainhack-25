{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d4c94-f0ea-479c-8ca4-7b0c7449b58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ca711",
   "metadata": {},
   "source": [
    "Changing Ultralytics conversion function to use 0 indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c338b4fc-e09f-499e-bb6f-3cc92ff761ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics.utils import DATASETS_DIR, LOGGER, NUM_THREADS, TQDM\n",
    "from ultralytics.utils.downloads import download, zip_directory\n",
    "from ultralytics.utils.files import increment_path\n",
    "\n",
    "\n",
    "def coco91_to_coco80_class():\n",
    "    \"\"\"\n",
    "    Converts 91-index COCO class IDs to 80-index COCO class IDs.\n",
    "\n",
    "    Returns:\n",
    "        (list): A list of 91 class IDs where the index represents the 80-index class ID and the value is the\n",
    "            corresponding 91-index class ID.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        0,\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        None,\n",
    "        11,\n",
    "        12,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        None,\n",
    "        24,\n",
    "        25,\n",
    "        None,\n",
    "        None,\n",
    "        26,\n",
    "        27,\n",
    "        28,\n",
    "        29,\n",
    "        30,\n",
    "        31,\n",
    "        32,\n",
    "        33,\n",
    "        34,\n",
    "        35,\n",
    "        36,\n",
    "        37,\n",
    "        38,\n",
    "        39,\n",
    "        None,\n",
    "        40,\n",
    "        41,\n",
    "        42,\n",
    "        43,\n",
    "        44,\n",
    "        45,\n",
    "        46,\n",
    "        47,\n",
    "        48,\n",
    "        49,\n",
    "        50,\n",
    "        51,\n",
    "        52,\n",
    "        53,\n",
    "        54,\n",
    "        55,\n",
    "        56,\n",
    "        57,\n",
    "        58,\n",
    "        59,\n",
    "        None,\n",
    "        60,\n",
    "        None,\n",
    "        None,\n",
    "        61,\n",
    "        None,\n",
    "        62,\n",
    "        63,\n",
    "        64,\n",
    "        65,\n",
    "        66,\n",
    "        67,\n",
    "        68,\n",
    "        69,\n",
    "        70,\n",
    "        71,\n",
    "        72,\n",
    "        None,\n",
    "        73,\n",
    "        74,\n",
    "        75,\n",
    "        76,\n",
    "        77,\n",
    "        78,\n",
    "        79,\n",
    "        None,\n",
    "    ]\n",
    "\n",
    "\n",
    "def coco80_to_coco91_class():\n",
    "    r\"\"\"\n",
    "    Converts 80-index (val2014) to 91-index (paper).\n",
    "    For details see https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/.\n",
    "\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> a = np.loadtxt(\"data/coco.names\", dtype=\"str\", delimiter=\"\\n\")\n",
    "        >>> b = np.loadtxt(\"data/coco_paper.names\", dtype=\"str\", delimiter=\"\\n\")\n",
    "\n",
    "        Convert the darknet to COCO format\n",
    "        >>> x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]\n",
    "\n",
    "        Convert the COCO to darknet format\n",
    "        >>> x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]\n",
    "    \"\"\"\n",
    "    return [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        24,\n",
    "        25,\n",
    "        27,\n",
    "        28,\n",
    "        31,\n",
    "        32,\n",
    "        33,\n",
    "        34,\n",
    "        35,\n",
    "        36,\n",
    "        37,\n",
    "        38,\n",
    "        39,\n",
    "        40,\n",
    "        41,\n",
    "        42,\n",
    "        43,\n",
    "        44,\n",
    "        46,\n",
    "        47,\n",
    "        48,\n",
    "        49,\n",
    "        50,\n",
    "        51,\n",
    "        52,\n",
    "        53,\n",
    "        54,\n",
    "        55,\n",
    "        56,\n",
    "        57,\n",
    "        58,\n",
    "        59,\n",
    "        60,\n",
    "        61,\n",
    "        62,\n",
    "        63,\n",
    "        64,\n",
    "        65,\n",
    "        67,\n",
    "        70,\n",
    "        72,\n",
    "        73,\n",
    "        74,\n",
    "        75,\n",
    "        76,\n",
    "        77,\n",
    "        78,\n",
    "        79,\n",
    "        80,\n",
    "        81,\n",
    "        82,\n",
    "        84,\n",
    "        85,\n",
    "        86,\n",
    "        87,\n",
    "        88,\n",
    "        89,\n",
    "        90,\n",
    "    ]\n",
    "\n",
    "\n",
    "def convert_coco(\n",
    "    labels_dir=\"../coco/annotations/\",\n",
    "    save_dir=\"coco_converted/\",\n",
    "    use_segments=False,\n",
    "    use_keypoints=False,\n",
    "    cls91to80=True,\n",
    "    lvis=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts COCO dataset annotations to a YOLO annotation format suitable for training YOLO models.\n",
    "\n",
    "    Args:\n",
    "        labels_dir (str, optional): Path to directory containing COCO dataset annotation files.\n",
    "        save_dir (str, optional): Path to directory to save results to.\n",
    "        use_segments (bool, optional): Whether to include segmentation masks in the output.\n",
    "        use_keypoints (bool, optional): Whether to include keypoint annotations in the output.\n",
    "        cls91to80 (bool, optional): Whether to map 91 COCO class IDs to the corresponding 80 COCO class IDs.\n",
    "        lvis (bool, optional): Whether to convert data in lvis dataset way.\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import convert_coco\n",
    "\n",
    "        Convert COCO annotations to YOLO format\n",
    "        >>> convert_coco(\"../datasets/coco/annotations/\", use_segments=True, use_keypoints=False, cls91to80=False)\n",
    "\n",
    "        Convert LVIS annotations to YOLO format\n",
    "        >>> convert_coco(\n",
    "        >>>    \"../datasets/lvis/annotations/\",\n",
    "        ...     use_segments=True,\n",
    "        ...     use_keypoints=False,\n",
    "        ...     cls91to80=False,\n",
    "        ...     lvis=True\n",
    "        ... )\n",
    "\n",
    "    Output:\n",
    "        Generates output files in the specified output directory.\n",
    "    \"\"\"\n",
    "    # Create dataset directory\n",
    "    save_dir = increment_path(save_dir)  # increment if save directory already exists\n",
    "    for p in save_dir / \"labels\", save_dir / \"images\":\n",
    "        p.mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Convert classes\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "\n",
    "    # Import json\n",
    "    for json_file in sorted(Path(labels_dir).resolve().glob(\"*.json\")):\n",
    "        lname = \"\" if lvis else json_file.stem.replace(\"instances_\", \"\")\n",
    "        fn = Path(save_dir) / \"labels\" / lname  # folder name\n",
    "        fn.mkdir(parents=True, exist_ok=True)\n",
    "        if lvis:\n",
    "            # NOTE: create folders for both train and val in advance,\n",
    "            # since LVIS val set contains images from COCO 2017 train in addition to the COCO 2017 val split.\n",
    "            (fn / \"train2017\").mkdir(parents=True, exist_ok=True)\n",
    "            (fn / \"val2017\").mkdir(parents=True, exist_ok=True)\n",
    "        with open(json_file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Create image dict\n",
    "        images = {f\"{x['id']:d}\": x for x in data[\"images\"]}\n",
    "        # Create image-annotations dict\n",
    "        annotations = defaultdict(list)\n",
    "        for ann in data[\"annotations\"]:\n",
    "            annotations[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "        image_txt = []\n",
    "        # Write labels file\n",
    "        for img_id, anns in TQDM(annotations.items(), desc=f\"Annotations {json_file}\"):\n",
    "            img = images[f\"{img_id:d}\"]\n",
    "            h, w = img[\"height\"], img[\"width\"]\n",
    "            f = str(Path(img[\"coco_url\"]).relative_to(\"http://images.cocodataset.org\")) if lvis else img[\"file_name\"]\n",
    "            if lvis:\n",
    "                image_txt.append(str(Path(\"./images\") / f))\n",
    "\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            keypoints = []\n",
    "            for ann in anns:\n",
    "                if ann.get(\"iscrowd\", False):\n",
    "                    continue\n",
    "                # The COCO box format is [top left x, top left y, width, height]\n",
    "                box = np.array(ann[\"bbox\"], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                box[[0, 2]] /= w  # normalize x\n",
    "                box[[1, 3]] /= h  # normalize y\n",
    "                if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                    continue\n",
    "\n",
    "                cls = coco80[ann[\"category_id\"] - 1] if cls91to80 else ann[\"category_id\"]   # class\n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                    if use_segments and ann.get(\"segmentation\") is not None:\n",
    "                        if len(ann[\"segmentation\"]) == 0:\n",
    "                            segments.append([])\n",
    "                            continue\n",
    "                        elif len(ann[\"segmentation\"]) > 1:\n",
    "                            s = merge_multi_segment(ann[\"segmentation\"])\n",
    "                            s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        else:\n",
    "                            s = [j for i in ann[\"segmentation\"] for j in i]  # all segments concatenated\n",
    "                            s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        s = [cls] + s\n",
    "                        segments.append(s)\n",
    "                    if use_keypoints and ann.get(\"keypoints\") is not None:\n",
    "                        keypoints.append(\n",
    "                            box + (np.array(ann[\"keypoints\"]).reshape(-1, 3) / np.array([w, h, 1])).reshape(-1).tolist()\n",
    "                        )\n",
    "\n",
    "            # Write\n",
    "            with open((fn / f).with_suffix(\".txt\"), \"a\", encoding=\"utf-8\") as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    if use_keypoints:\n",
    "                        line = (*(keypoints[i]),)  # cls, box, keypoints\n",
    "                    else:\n",
    "                        line = (\n",
    "                            *(segments[i] if use_segments and len(segments[i]) > 0 else bboxes[i]),\n",
    "                        )  # cls, box or segments\n",
    "                    file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")\n",
    "\n",
    "        if lvis:\n",
    "            filename = Path(save_dir) / json_file.name.replace(\"lvis_v1_\", \"\").replace(\".json\", \".txt\")\n",
    "            with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.writelines(f\"{line}\\n\" for line in image_txt)\n",
    "\n",
    "    LOGGER.info(f\"{'LVIS' if lvis else 'COCO'} data converted successfully.\\nResults saved to {save_dir.resolve()}\")\n",
    "\n",
    "\n",
    "def convert_segment_masks_to_yolo_seg(masks_dir, output_dir, classes):\n",
    "    \"\"\"\n",
    "    Converts a dataset of segmentation mask images to the YOLO segmentation format.\n",
    "\n",
    "    This function takes the directory containing the binary format mask images and converts them into YOLO segmentation format.\n",
    "    The converted masks are saved in the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        masks_dir (str): The path to the directory where all mask images (png, jpg) are stored.\n",
    "        output_dir (str): The path to the directory where the converted YOLO segmentation masks will be stored.\n",
    "        classes (int): Total classes in the dataset i.e. for COCO classes=80\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import convert_segment_masks_to_yolo_seg\n",
    "\n",
    "        The classes here is the total classes in the dataset, for COCO dataset we have 80 classes\n",
    "        >>> convert_segment_masks_to_yolo_seg(\"path/to/masks_directory\", \"path/to/output/directory\", classes=80)\n",
    "\n",
    "    Notes:\n",
    "        The expected directory structure for the masks is:\n",
    "\n",
    "            - masks\n",
    "                â”œâ”€ mask_image_01.png or mask_image_01.jpg\n",
    "                â”œâ”€ mask_image_02.png or mask_image_02.jpg\n",
    "                â”œâ”€ mask_image_03.png or mask_image_03.jpg\n",
    "                â””â”€ mask_image_04.png or mask_image_04.jpg\n",
    "\n",
    "        After execution, the labels will be organized in the following structure:\n",
    "\n",
    "            - output_dir\n",
    "                â”œâ”€ mask_yolo_01.txt\n",
    "                â”œâ”€ mask_yolo_02.txt\n",
    "                â”œâ”€ mask_yolo_03.txt\n",
    "                â””â”€ mask_yolo_04.txt\n",
    "    \"\"\"\n",
    "    pixel_to_class_mapping = {i + 1: i for i in range(classes)}\n",
    "    for mask_path in Path(masks_dir).iterdir():\n",
    "        if mask_path.suffix in {\".png\", \".jpg\"}:\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)  # Read the mask image in grayscale\n",
    "            img_height, img_width = mask.shape  # Get image dimensions\n",
    "            LOGGER.info(f\"Processing {mask_path} imgsz = {img_height} x {img_width}\")\n",
    "\n",
    "            unique_values = np.unique(mask)  # Get unique pixel values representing different classes\n",
    "            yolo_format_data = []\n",
    "\n",
    "            for value in unique_values:\n",
    "                if value == 0:\n",
    "                    continue  # Skip background\n",
    "                class_index = pixel_to_class_mapping.get(value, -1)\n",
    "                if class_index == -1:\n",
    "                    LOGGER.warning(f\"Unknown class for pixel value {value} in file {mask_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Create a binary mask for the current class and find contours\n",
    "                contours, _ = cv2.findContours(\n",
    "                    (mask == value).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "                )  # Find contours\n",
    "\n",
    "                for contour in contours:\n",
    "                    if len(contour) >= 3:  # YOLO requires at least 3 points for a valid segmentation\n",
    "                        contour = contour.squeeze()  # Remove single-dimensional entries\n",
    "                        yolo_format = [class_index]\n",
    "                        for point in contour:\n",
    "                            # Normalize the coordinates\n",
    "                            yolo_format.append(round(point[0] / img_width, 6))  # Rounding to 6 decimal places\n",
    "                            yolo_format.append(round(point[1] / img_height, 6))\n",
    "                        yolo_format_data.append(yolo_format)\n",
    "            # Save Ultralytics YOLO format data to file\n",
    "            output_path = Path(output_dir) / f\"{mask_path.stem}.txt\"\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                for item in yolo_format_data:\n",
    "                    line = \" \".join(map(str, item))\n",
    "                    file.write(line + \"\\n\")\n",
    "            LOGGER.info(f\"Processed and stored at {output_path} imgsz = {img_height} x {img_width}\")\n",
    "\n",
    "\n",
    "def convert_dota_to_yolo_obb(dota_root_path: str):\n",
    "    \"\"\"\n",
    "    Converts DOTA dataset annotations to YOLO OBB (Oriented Bounding Box) format.\n",
    "\n",
    "    The function processes images in the 'train' and 'val' folders of the DOTA dataset. For each image, it reads the\n",
    "    associated label from the original labels directory and writes new labels in YOLO OBB format to a new directory.\n",
    "\n",
    "    Args:\n",
    "        dota_root_path (str): The root directory path of the DOTA dataset.\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import convert_dota_to_yolo_obb\n",
    "        >>> convert_dota_to_yolo_obb(\"path/to/DOTA\")\n",
    "\n",
    "    Notes:\n",
    "        The directory structure assumed for the DOTA dataset:\n",
    "\n",
    "            - DOTA\n",
    "                â”œâ”€ images\n",
    "                â”‚   â”œâ”€ train\n",
    "                â”‚   â””â”€ val\n",
    "                â””â”€ labels\n",
    "                    â”œâ”€ train_original\n",
    "                    â””â”€ val_original\n",
    "\n",
    "        After execution, the function will organize the labels into:\n",
    "\n",
    "            - DOTA\n",
    "                â””â”€ labels\n",
    "                    â”œâ”€ train\n",
    "                    â””â”€ val\n",
    "    \"\"\"\n",
    "    dota_root_path = Path(dota_root_path)\n",
    "\n",
    "    # Class names to indices mapping\n",
    "    class_mapping = {\n",
    "        \"plane\": 0,\n",
    "        \"ship\": 1,\n",
    "        \"storage-tank\": 2,\n",
    "        \"baseball-diamond\": 3,\n",
    "        \"tennis-court\": 4,\n",
    "        \"basketball-court\": 5,\n",
    "        \"ground-track-field\": 6,\n",
    "        \"harbor\": 7,\n",
    "        \"bridge\": 8,\n",
    "        \"large-vehicle\": 9,\n",
    "        \"small-vehicle\": 10,\n",
    "        \"helicopter\": 11,\n",
    "        \"roundabout\": 12,\n",
    "        \"soccer-ball-field\": 13,\n",
    "        \"swimming-pool\": 14,\n",
    "        \"container-crane\": 15,\n",
    "        \"airport\": 16,\n",
    "        \"helipad\": 17,\n",
    "    }\n",
    "\n",
    "    def convert_label(image_name, image_width, image_height, orig_label_dir, save_dir):\n",
    "        \"\"\"Converts a single image's DOTA annotation to YOLO OBB format and saves it to a specified directory.\"\"\"\n",
    "        orig_label_path = orig_label_dir / f\"{image_name}.txt\"\n",
    "        save_path = save_dir / f\"{image_name}.txt\"\n",
    "\n",
    "        with orig_label_path.open(\"r\") as f, save_path.open(\"w\") as g:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 9:\n",
    "                    continue\n",
    "                class_name = parts[8]\n",
    "                class_idx = class_mapping[class_name]\n",
    "                coords = [float(p) for p in parts[:8]]\n",
    "                normalized_coords = [\n",
    "                    coords[i] / image_width if i % 2 == 0 else coords[i] / image_height for i in range(8)\n",
    "                ]\n",
    "                formatted_coords = [f\"{coord:.6g}\" for coord in normalized_coords]\n",
    "                g.write(f\"{class_idx} {' '.join(formatted_coords)}\\n\")\n",
    "\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        image_dir = dota_root_path / \"images\" / phase\n",
    "        orig_label_dir = dota_root_path / \"labels\" / f\"{phase}_original\"\n",
    "        save_dir = dota_root_path / \"labels\" / phase\n",
    "\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        image_paths = list(image_dir.iterdir())\n",
    "        for image_path in TQDM(image_paths, desc=f\"Processing {phase} images\"):\n",
    "            if image_path.suffix != \".png\":\n",
    "                continue\n",
    "            image_name_without_ext = image_path.stem\n",
    "            img = cv2.imread(str(image_path))\n",
    "            h, w = img.shape[:2]\n",
    "            convert_label(image_name_without_ext, w, h, orig_label_dir, save_dir)\n",
    "\n",
    "\n",
    "def min_index(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Find a pair of indexes with the shortest distance between two arrays of 2D points.\n",
    "\n",
    "    Args:\n",
    "        arr1 (np.ndarray): A NumPy array of shape (N, 2) representing N 2D points.\n",
    "        arr2 (np.ndarray): A NumPy array of shape (M, 2) representing M 2D points.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): A tuple containing the indexes of the points with the shortest distance in arr1 and arr2 respectively.\n",
    "    \"\"\"\n",
    "    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)\n",
    "    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)\n",
    "\n",
    "\n",
    "def merge_multi_segment(segments):\n",
    "    \"\"\"\n",
    "    Merge multiple segments into one list by connecting the coordinates with the minimum distance between each segment.\n",
    "    This function connects these coordinates with a thin line to merge all segments into one.\n",
    "\n",
    "    Args:\n",
    "        segments (List[List]): Original segmentations in COCO's JSON file.\n",
    "                               Each element is a list of coordinates, like [segmentation1, segmentation2,...].\n",
    "\n",
    "    Returns:\n",
    "        s (List[np.ndarray]): A list of connected segments represented as NumPy arrays.\n",
    "    \"\"\"\n",
    "    s = []\n",
    "    segments = [np.array(i).reshape(-1, 2) for i in segments]\n",
    "    idx_list = [[] for _ in range(len(segments))]\n",
    "\n",
    "    # Record the indexes with min distance between each segment\n",
    "    for i in range(1, len(segments)):\n",
    "        idx1, idx2 = min_index(segments[i - 1], segments[i])\n",
    "        idx_list[i - 1].append(idx1)\n",
    "        idx_list[i].append(idx2)\n",
    "\n",
    "    # Use two round to connect all the segments\n",
    "    for k in range(2):\n",
    "        # Forward connection\n",
    "        if k == 0:\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                # Middle segments have two indexes, reverse the index of middle segments\n",
    "                if len(idx) == 2 and idx[0] > idx[1]:\n",
    "                    idx = idx[::-1]\n",
    "                    segments[i] = segments[i][::-1, :]\n",
    "\n",
    "                segments[i] = np.roll(segments[i], -idx[0], axis=0)\n",
    "                segments[i] = np.concatenate([segments[i], segments[i][:1]])\n",
    "                # Deal with the first segment and the last one\n",
    "                if i in {0, len(idx_list) - 1}:\n",
    "                    s.append(segments[i])\n",
    "                else:\n",
    "                    idx = [0, idx[1] - idx[0]]\n",
    "                    s.append(segments[i][idx[0] : idx[1] + 1])\n",
    "\n",
    "        else:\n",
    "            for i in range(len(idx_list) - 1, -1, -1):\n",
    "                if i not in {0, len(idx_list) - 1}:\n",
    "                    idx = idx_list[i]\n",
    "                    nidx = abs(idx[1] - idx[0])\n",
    "                    s.append(segments[i][nidx:])\n",
    "    return s\n",
    "\n",
    "\n",
    "def yolo_bbox2segment(im_dir, save_dir=None, sam_model=\"sam_b.pt\", device=None):\n",
    "    \"\"\"\n",
    "    Converts existing object detection dataset (bounding boxes) to segmentation dataset or oriented bounding box (OBB)\n",
    "    in YOLO format. Generates segmentation data using SAM auto-annotator as needed.\n",
    "\n",
    "    Args:\n",
    "        im_dir (str | Path): Path to image directory to convert.\n",
    "        save_dir (str | Path): Path to save the generated labels, labels will be saved\n",
    "            into `labels-segment` in the same directory level of `im_dir` if save_dir is None.\n",
    "        sam_model (str): Segmentation model to use for intermediate segmentation data.\n",
    "        device (int | str): The specific device to run SAM models.\n",
    "\n",
    "    Notes:\n",
    "        The input directory structure assumed for dataset:\n",
    "\n",
    "            - im_dir\n",
    "                â”œâ”€ 001.jpg\n",
    "                â”œâ”€ ...\n",
    "                â””â”€ NNN.jpg\n",
    "            - labels\n",
    "                â”œâ”€ 001.txt\n",
    "                â”œâ”€ ...\n",
    "                â””â”€ NNN.txt\n",
    "    \"\"\"\n",
    "    from ultralytics import SAM\n",
    "    from ultralytics.data import YOLODataset\n",
    "    from ultralytics.utils.ops import xywh2xyxy\n",
    "\n",
    "    # NOTE: add placeholder to pass class index check\n",
    "    dataset = YOLODataset(im_dir, data=dict(names=list(range(1000))))\n",
    "    if len(dataset.labels[0][\"segments\"]) > 0:  # if it's segment data\n",
    "        LOGGER.info(\"Segmentation labels detected, no need to generate new ones!\")\n",
    "        return\n",
    "\n",
    "    LOGGER.info(\"Detection labels detected, generating segment labels by SAM model!\")\n",
    "    sam_model = SAM(sam_model)\n",
    "    for label in TQDM(dataset.labels, total=len(dataset.labels), desc=\"Generating segment labels\"):\n",
    "        h, w = label[\"shape\"]\n",
    "        boxes = label[\"bboxes\"]\n",
    "        if len(boxes) == 0:  # skip empty labels\n",
    "            continue\n",
    "        boxes[:, [0, 2]] *= w\n",
    "        boxes[:, [1, 3]] *= h\n",
    "        im = cv2.imread(label[\"im_file\"])\n",
    "        sam_results = sam_model(im, bboxes=xywh2xyxy(boxes), verbose=False, save=False, device=device)\n",
    "        label[\"segments\"] = sam_results[0].masks.xyn\n",
    "\n",
    "    save_dir = Path(save_dir) if save_dir else Path(im_dir).parent / \"labels-segment\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for label in dataset.labels:\n",
    "        texts = []\n",
    "        lb_name = Path(label[\"im_file\"]).with_suffix(\".txt\").name\n",
    "        txt_file = save_dir / lb_name\n",
    "        cls = label[\"cls\"]\n",
    "        for i, s in enumerate(label[\"segments\"]):\n",
    "            if len(s) == 0:\n",
    "                continue\n",
    "            line = (int(cls[i]), *s.reshape(-1))\n",
    "            texts.append((\"%g \" * len(line)).rstrip() % line)\n",
    "        with open(txt_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(text + \"\\n\" for text in texts)\n",
    "    LOGGER.info(f\"Generated segment labels saved in {save_dir}\")\n",
    "\n",
    "\n",
    "def create_synthetic_coco_dataset():\n",
    "    \"\"\"\n",
    "    Creates a synthetic COCO dataset with random images based on filenames from label lists.\n",
    "\n",
    "    This function downloads COCO labels, reads image filenames from label list files,\n",
    "    creates synthetic images for train2017 and val2017 subsets, and organizes\n",
    "    them in the COCO dataset structure. It uses multithreading to generate images efficiently.\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import create_synthetic_coco_dataset\n",
    "        >>> create_synthetic_coco_dataset()\n",
    "\n",
    "    Notes:\n",
    "        - Requires internet connection to download label files.\n",
    "        - Generates random RGB images of varying sizes (480x480 to 640x640 pixels).\n",
    "        - Existing test2017 directory is removed as it's not needed.\n",
    "        - Reads image filenames from train2017.txt and val2017.txt files.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_synthetic_image(image_file):\n",
    "        \"\"\"Generates synthetic images with random sizes and colors for dataset augmentation or testing purposes.\"\"\"\n",
    "        if not image_file.exists():\n",
    "            size = (random.randint(480, 640), random.randint(480, 640))\n",
    "            Image.new(\n",
    "                \"RGB\",\n",
    "                size=size,\n",
    "                color=(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)),\n",
    "            ).save(image_file)\n",
    "\n",
    "    # Download labels\n",
    "    dir = DATASETS_DIR / \"coco\"\n",
    "    url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/\"\n",
    "    label_zip = \"coco2017labels-segments.zip\"\n",
    "    download([url + label_zip], dir=dir.parent)\n",
    "\n",
    "    # Create synthetic images\n",
    "    shutil.rmtree(dir / \"labels\" / \"test2017\", ignore_errors=True)  # Remove test2017 directory as not needed\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        for subset in [\"train2017\", \"val2017\"]:\n",
    "            subset_dir = dir / \"images\" / subset\n",
    "            subset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Read image filenames from label list file\n",
    "            label_list_file = dir / f\"{subset}.txt\"\n",
    "            if label_list_file.exists():\n",
    "                with open(label_list_file, encoding=\"utf-8\") as f:\n",
    "                    image_files = [dir / line.strip() for line in f]\n",
    "\n",
    "                # Submit all tasks\n",
    "                futures = [executor.submit(create_synthetic_image, image_file) for image_file in image_files]\n",
    "                for _ in TQDM(as_completed(futures), total=len(futures), desc=f\"Generating images for {subset}\"):\n",
    "                    pass  # The actual work is done in the background\n",
    "            else:\n",
    "                LOGGER.warning(f\"Labels file {label_list_file} does not exist. Skipping image creation for {subset}.\")\n",
    "\n",
    "    LOGGER.info(\"Synthetic COCO dataset created successfully.\")\n",
    "\n",
    "\n",
    "def convert_to_multispectral(path, n_channels=10, replace=False, zip=False):\n",
    "    \"\"\"\n",
    "    Convert RGB images to multispectral images by interpolating across wavelength bands.\n",
    "\n",
    "    This function takes RGB images and interpolates them to create multispectral images with a specified number\n",
    "    of channels. It can process either a single image or a directory of images.\n",
    "\n",
    "    Args:\n",
    "        path (str | Path): Path to an image file or directory containing images to convert.\n",
    "        n_channels (int): Number of spectral channels to generate in the output image.\n",
    "        replace (bool): Whether to replace the original image file with the converted one.\n",
    "        zip (bool): Whether to zip the converted images into a zip file.\n",
    "\n",
    "    Examples:\n",
    "        >>> # Convert a single image\n",
    "        >>> convert_to_multispectral(\"path/to/image.jpg\", n_channels=10)\n",
    "        >>> # Convert a dataset\n",
    "        >>> convert_to_multispectral(\"../datasets/coco8\", n_channels=10)\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    from ultralytics.data.utils import IMG_FORMATS\n",
    "\n",
    "    path = Path(path)\n",
    "    if path.is_dir():\n",
    "        # Process directory\n",
    "        im_files = sum([list(path.rglob(f\"*.{ext}\")) for ext in (IMG_FORMATS - {\"tif\", \"tiff\"})], [])\n",
    "        for im_path in im_files:\n",
    "            try:\n",
    "                convert_to_multispectral(im_path, n_channels)\n",
    "                if replace:\n",
    "                    im_path.unlink()\n",
    "            except Exception as e:\n",
    "                LOGGER.info(f\"Error converting {im_path}: {e}\")\n",
    "\n",
    "        if zip:\n",
    "            zip_directory(path)\n",
    "    else:\n",
    "        # Process a single image\n",
    "        output_path = path.with_suffix(\".tiff\")\n",
    "        img = cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Interpolate all pixels at once\n",
    "        rgb_wavelengths = np.array([650, 510, 475])  # R, G, B wavelengths (nm)\n",
    "        target_wavelengths = np.linspace(450, 700, n_channels)\n",
    "        f = interp1d(rgb_wavelengths.T, img, kind=\"linear\", bounds_error=False, fill_value=\"extrapolate\")\n",
    "        multispectral = f(target_wavelengths)\n",
    "        cv2.imwritemulti(str(output_path), np.clip(multispectral, 0, 255).astype(np.uint8).transpose(2, 0, 1))\n",
    "        LOGGER.info(f\"Converted {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f005ba25-ee09-41d0-8462-1ca5d583d781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /home/jupyter/til25-import-torch/cv/json_dataset/annotations.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19253/19253 [00:02<00:00, 7335.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/jupyter/til25-import-torch/cv/yaml_dataset3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For keypoints data (like person_keypoints_val2017.json)\n",
    "convert_coco(\n",
    "    labels_dir=\"/home/jupyter/til25-import-torch/cv/json_dataset\",  # Directory containing your json file\n",
    "    save_dir=\"/home/jupyter/til25-import-torch/cv/yaml_dataset\",\n",
    "    # use_keypoints=False,  # Since you're using keypoints data\n",
    "    use_segments=False,\n",
    "    cls91to80=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec21c6d-5b87-4674-9a61-fbc72d98fffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified split complete: 15402 train, 3851 val\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Paths\n",
    "images_src = Path(\"/home/jupyter/til25-import-torch/cv/json_dataset/images\")\n",
    "labels_src = Path(\"/home/jupyter/til25-import-torch/cv/yaml_dataset/labels/annotations\")\n",
    "dst_base = Path(\"/home/jupyter/til25-import-torch/cv/cv_dataset_split\")\n",
    "\n",
    "# Make sure output folders exist\n",
    "for split in ['train/images', 'train/labels', 'val/images', 'val/labels']:\n",
    "    (dst_base / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Gather image files and determine dominant class for stratification\n",
    "image_paths = list(images_src.glob(\"*.jpg\")) + list(images_src.glob(\"*.png\")) + list(images_src.glob(\"*.jpeg\"))\n",
    "image_names = []\n",
    "class_labels = []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    label_file = labels_src / (img_path.stem + \".txt\")\n",
    "    if not label_file.exists():\n",
    "        continue  # skip if no label\n",
    "\n",
    "    try:\n",
    "        with open(label_file, 'r') as f:\n",
    "            class_ids = [int(line.strip().split()[0]) for line in f.readlines() if line.strip()]\n",
    "        if not class_ids:\n",
    "            continue\n",
    "        dominant_class = Counter(class_ids).most_common(1)[0][0]\n",
    "        image_names.append(img_path.name)\n",
    "        class_labels.append(dominant_class)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {label_file}: {e}\")\n",
    "\n",
    "# Stratified split\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(splitter.split(image_names, class_labels))\n",
    "\n",
    "# Helper to symlink image + label\n",
    "def symlink_subset(indices, split):\n",
    "    for i in indices:\n",
    "        img_name = image_names[i]\n",
    "        label_name = img_name.rsplit('.', 1)[0] + \".txt\"\n",
    "\n",
    "        img_src = images_src / img_name\n",
    "        lbl_src = labels_src / label_name\n",
    "\n",
    "        img_dst = dst_base / split / \"images\" / img_name\n",
    "        lbl_dst = dst_base / split / \"labels\" / label_name\n",
    "\n",
    "        try:\n",
    "            os.symlink(img_src.resolve(), img_dst)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        if lbl_src.exists():\n",
    "            try:\n",
    "                os.symlink(lbl_src.resolve(), lbl_dst)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "\n",
    "# Create symlinks\n",
    "symlink_subset(train_idx, \"train\")\n",
    "symlink_subset(val_idx, \"val\")\n",
    "\n",
    "print(f\"Stratified split complete: {len(train_idx)} train, {len(val_idx)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fb645",
   "metadata": {},
   "source": [
    "about 800 images were missing after the split so an analysis function was used to determine the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b07e46c-1985-433d-b405-37d9cca3446d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def analyze_coco_annotations(\n",
    "    json_path,\n",
    "    use_segments=False,\n",
    "    use_keypoints=False\n",
    "):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "    annotations_by_image = defaultdict(list)\n",
    "    for ann in data[\"annotations\"]:\n",
    "        annotations_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "    total_images = len(images)\n",
    "    total_annotated_images = 0\n",
    "    skipped_ann_count = 0\n",
    "\n",
    "    print(f\"\\nðŸ” Analyzing {json_path}\")\n",
    "    print(f\"Total images in JSON: {total_images}\")\n",
    "    print(\"Logging skipped annotations...\\n\")\n",
    "\n",
    "    for img_id, img in images.items():\n",
    "        anns = annotations_by_image.get(img_id, [])\n",
    "        if not anns:\n",
    "            print(f\"ðŸš« Image {img['file_name']} has no annotations.\")\n",
    "            continue\n",
    "\n",
    "        valid = False\n",
    "        for ann in anns:\n",
    "            reason = None\n",
    "\n",
    "            if ann.get(\"iscrowd\", 0) == 1:\n",
    "                reason = \"iscrowd=1\"\n",
    "            elif \"bbox\" not in ann or not isinstance(ann[\"bbox\"], list) or len(ann[\"bbox\"]) != 4:\n",
    "                reason = \"Missing or invalid bbox\"\n",
    "            elif ann[\"bbox\"][2] <= 0 or ann[\"bbox\"][3] <= 0:\n",
    "                reason = f\"Invalid bbox size: w={ann['bbox'][2]}, h={ann['bbox'][3]}\"\n",
    "            elif \"category_id\" not in ann:\n",
    "                reason = \"Missing category_id\"\n",
    "            elif use_segments and (\"segmentation\" not in ann or not ann[\"segmentation\"] or not isinstance(ann[\"segmentation\"], list)):\n",
    "                reason = \"Empty or malformed segmentation\"\n",
    "            elif use_keypoints and (\"keypoints\" not in ann or len(ann[\"keypoints\"]) % 3 != 0):\n",
    "                reason = \"Malformed keypoints\"\n",
    "\n",
    "            if reason:\n",
    "                skipped_ann_count += 1\n",
    "                print(f\"âŒ Skipping ann ID {ann['id']} in image '{img['file_name']}': {reason}\")\n",
    "            else:\n",
    "                valid = True\n",
    "\n",
    "        if valid:\n",
    "            total_annotated_images += 1\n",
    "\n",
    "    print(\"\\nðŸ“Š Summary:\")\n",
    "    print(f\"ðŸ–¼ï¸  Total images: {total_images}\")\n",
    "    print(f\"âœ… Images with at least one valid annotation: {total_annotated_images}\")\n",
    "    print(f\"ðŸš« Images with no valid annotations: {total_images - total_annotated_images}\")\n",
    "    print(f\"âŒ Skipped annotations: {skipped_ann_count}\\n\")\n",
    "\n",
    "# Example usage\n",
    "# analyze_coco_annotations(\"instances_train2017.json\", use_segments=True, use_keypoints=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7543394-96e5-4672-acfd-6e77a80c992c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Analyzing ./json_dataset/annotations.json\n",
      "Total images in JSON: 20000\n",
      "Logging skipped annotations...\n",
      "\n",
      "ðŸš« Image 17059.jpg has no annotations.\n",
      "ðŸš« Image 8021.jpg has no annotations.\n",
      "ðŸš« Image 6320.jpg has no annotations.\n",
      "ðŸš« Image 5595.jpg has no annotations.\n",
      "ðŸš« Image 3738.jpg has no annotations.\n",
      "ðŸš« Image 8104.jpg has no annotations.\n",
      "ðŸš« Image 10552.jpg has no annotations.\n",
      "ðŸš« Image 155.jpg has no annotations.\n",
      "ðŸš« Image 11020.jpg has no annotations.\n",
      "ðŸš« Image 15269.jpg has no annotations.\n",
      "ðŸš« Image 7335.jpg has no annotations.\n",
      "ðŸš« Image 16178.jpg has no annotations.\n",
      "ðŸš« Image 14970.jpg has no annotations.\n",
      "ðŸš« Image 9109.jpg has no annotations.\n",
      "ðŸš« Image 5972.jpg has no annotations.\n",
      "ðŸš« Image 19698.jpg has no annotations.\n",
      "ðŸš« Image 8502.jpg has no annotations.\n",
      "ðŸš« Image 11820.jpg has no annotations.\n",
      "ðŸš« Image 9176.jpg has no annotations.\n",
      "ðŸš« Image 11470.jpg has no annotations.\n",
      "ðŸš« Image 12980.jpg has no annotations.\n",
      "ðŸš« Image 2719.jpg has no annotations.\n",
      "ðŸš« Image 7413.jpg has no annotations.\n",
      "ðŸš« Image 15125.jpg has no annotations.\n",
      "ðŸš« Image 10290.jpg has no annotations.\n",
      "ðŸš« Image 19278.jpg has no annotations.\n",
      "ðŸš« Image 5051.jpg has no annotations.\n",
      "ðŸš« Image 292.jpg has no annotations.\n",
      "ðŸš« Image 2103.jpg has no annotations.\n",
      "ðŸš« Image 7265.jpg has no annotations.\n",
      "ðŸš« Image 4759.jpg has no annotations.\n",
      "ðŸš« Image 10545.jpg has no annotations.\n",
      "ðŸš« Image 3163.jpg has no annotations.\n",
      "ðŸš« Image 16820.jpg has no annotations.\n",
      "ðŸš« Image 4558.jpg has no annotations.\n",
      "ðŸš« Image 8813.jpg has no annotations.\n",
      "ðŸš« Image 15681.jpg has no annotations.\n",
      "ðŸš« Image 17012.jpg has no annotations.\n",
      "ðŸš« Image 6390.jpg has no annotations.\n",
      "ðŸš« Image 11393.jpg has no annotations.\n",
      "ðŸš« Image 2361.jpg has no annotations.\n",
      "ðŸš« Image 16529.jpg has no annotations.\n",
      "ðŸš« Image 15663.jpg has no annotations.\n",
      "ðŸš« Image 6441.jpg has no annotations.\n",
      "ðŸš« Image 10278.jpg has no annotations.\n",
      "ðŸš« Image 6061.jpg has no annotations.\n",
      "ðŸš« Image 3832.jpg has no annotations.\n",
      "ðŸš« Image 19127.jpg has no annotations.\n",
      "ðŸš« Image 13.jpg has no annotations.\n",
      "ðŸš« Image 15203.jpg has no annotations.\n",
      "ðŸš« Image 18602.jpg has no annotations.\n",
      "ðŸš« Image 17843.jpg has no annotations.\n",
      "ðŸš« Image 8245.jpg has no annotations.\n",
      "ðŸš« Image 20.jpg has no annotations.\n",
      "ðŸš« Image 86.jpg has no annotations.\n",
      "ðŸš« Image 11745.jpg has no annotations.\n",
      "ðŸš« Image 2531.jpg has no annotations.\n",
      "ðŸš« Image 7032.jpg has no annotations.\n",
      "ðŸš« Image 12498.jpg has no annotations.\n",
      "ðŸš« Image 12328.jpg has no annotations.\n",
      "ðŸš« Image 3774.jpg has no annotations.\n",
      "ðŸš« Image 5272.jpg has no annotations.\n",
      "ðŸš« Image 10210.jpg has no annotations.\n",
      "ðŸš« Image 10007.jpg has no annotations.\n",
      "ðŸš« Image 6370.jpg has no annotations.\n",
      "ðŸš« Image 18041.jpg has no annotations.\n",
      "ðŸš« Image 18361.jpg has no annotations.\n",
      "ðŸš« Image 1052.jpg has no annotations.\n",
      "ðŸš« Image 8248.jpg has no annotations.\n",
      "ðŸš« Image 11653.jpg has no annotations.\n",
      "ðŸš« Image 18952.jpg has no annotations.\n",
      "ðŸš« Image 4011.jpg has no annotations.\n",
      "ðŸš« Image 3359.jpg has no annotations.\n",
      "ðŸš« Image 4730.jpg has no annotations.\n",
      "ðŸš« Image 3348.jpg has no annotations.\n",
      "ðŸš« Image 8793.jpg has no annotations.\n",
      "ðŸš« Image 5331.jpg has no annotations.\n",
      "ðŸš« Image 18547.jpg has no annotations.\n",
      "ðŸš« Image 14299.jpg has no annotations.\n",
      "ðŸš« Image 16712.jpg has no annotations.\n",
      "ðŸš« Image 10749.jpg has no annotations.\n",
      "ðŸš« Image 4973.jpg has no annotations.\n",
      "ðŸš« Image 4393.jpg has no annotations.\n",
      "ðŸš« Image 14617.jpg has no annotations.\n",
      "ðŸš« Image 13977.jpg has no annotations.\n",
      "ðŸš« Image 17754.jpg has no annotations.\n",
      "ðŸš« Image 4702.jpg has no annotations.\n",
      "ðŸš« Image 649.jpg has no annotations.\n",
      "ðŸš« Image 555.jpg has no annotations.\n",
      "ðŸš« Image 7169.jpg has no annotations.\n",
      "ðŸš« Image 4242.jpg has no annotations.\n",
      "ðŸš« Image 14850.jpg has no annotations.\n",
      "ðŸš« Image 19233.jpg has no annotations.\n",
      "ðŸš« Image 8615.jpg has no annotations.\n",
      "ðŸš« Image 8444.jpg has no annotations.\n",
      "ðŸš« Image 9602.jpg has no annotations.\n",
      "ðŸš« Image 13223.jpg has no annotations.\n",
      "ðŸš« Image 9184.jpg has no annotations.\n",
      "ðŸš« Image 3411.jpg has no annotations.\n",
      "ðŸš« Image 17360.jpg has no annotations.\n",
      "ðŸš« Image 13174.jpg has no annotations.\n",
      "ðŸš« Image 19859.jpg has no annotations.\n",
      "ðŸš« Image 19641.jpg has no annotations.\n",
      "ðŸš« Image 3377.jpg has no annotations.\n",
      "ðŸš« Image 5586.jpg has no annotations.\n",
      "ðŸš« Image 14115.jpg has no annotations.\n",
      "ðŸš« Image 12859.jpg has no annotations.\n",
      "ðŸš« Image 9972.jpg has no annotations.\n",
      "ðŸš« Image 18954.jpg has no annotations.\n",
      "ðŸš« Image 13898.jpg has no annotations.\n",
      "ðŸš« Image 5668.jpg has no annotations.\n",
      "ðŸš« Image 7775.jpg has no annotations.\n",
      "ðŸš« Image 10562.jpg has no annotations.\n",
      "ðŸš« Image 15143.jpg has no annotations.\n",
      "ðŸš« Image 11557.jpg has no annotations.\n",
      "ðŸš« Image 7738.jpg has no annotations.\n",
      "ðŸš« Image 18168.jpg has no annotations.\n",
      "ðŸš« Image 3675.jpg has no annotations.\n",
      "ðŸš« Image 6032.jpg has no annotations.\n",
      "ðŸš« Image 15715.jpg has no annotations.\n",
      "ðŸš« Image 9982.jpg has no annotations.\n",
      "ðŸš« Image 11027.jpg has no annotations.\n",
      "ðŸš« Image 4340.jpg has no annotations.\n",
      "ðŸš« Image 2126.jpg has no annotations.\n",
      "ðŸš« Image 17514.jpg has no annotations.\n",
      "ðŸš« Image 5653.jpg has no annotations.\n",
      "ðŸš« Image 246.jpg has no annotations.\n",
      "ðŸš« Image 8018.jpg has no annotations.\n",
      "ðŸš« Image 17769.jpg has no annotations.\n",
      "ðŸš« Image 12831.jpg has no annotations.\n",
      "ðŸš« Image 4322.jpg has no annotations.\n",
      "ðŸš« Image 6331.jpg has no annotations.\n",
      "ðŸš« Image 16757.jpg has no annotations.\n",
      "ðŸš« Image 10700.jpg has no annotations.\n",
      "ðŸš« Image 10830.jpg has no annotations.\n",
      "ðŸš« Image 4824.jpg has no annotations.\n",
      "ðŸš« Image 16594.jpg has no annotations.\n",
      "ðŸš« Image 2319.jpg has no annotations.\n",
      "ðŸš« Image 19951.jpg has no annotations.\n",
      "ðŸš« Image 393.jpg has no annotations.\n",
      "ðŸš« Image 16760.jpg has no annotations.\n",
      "ðŸš« Image 15077.jpg has no annotations.\n",
      "ðŸš« Image 19718.jpg has no annotations.\n",
      "ðŸš« Image 2440.jpg has no annotations.\n",
      "ðŸš« Image 12621.jpg has no annotations.\n",
      "ðŸš« Image 19862.jpg has no annotations.\n",
      "ðŸš« Image 9924.jpg has no annotations.\n",
      "ðŸš« Image 5390.jpg has no annotations.\n",
      "ðŸš« Image 6049.jpg has no annotations.\n",
      "ðŸš« Image 15590.jpg has no annotations.\n",
      "ðŸš« Image 17499.jpg has no annotations.\n",
      "ðŸš« Image 10316.jpg has no annotations.\n",
      "ðŸš« Image 3106.jpg has no annotations.\n",
      "ðŸš« Image 8428.jpg has no annotations.\n",
      "ðŸš« Image 19709.jpg has no annotations.\n",
      "ðŸš« Image 17945.jpg has no annotations.\n",
      "ðŸš« Image 10966.jpg has no annotations.\n",
      "ðŸš« Image 3560.jpg has no annotations.\n",
      "ðŸš« Image 8782.jpg has no annotations.\n",
      "ðŸš« Image 15166.jpg has no annotations.\n",
      "ðŸš« Image 14205.jpg has no annotations.\n",
      "ðŸš« Image 17036.jpg has no annotations.\n",
      "ðŸš« Image 7895.jpg has no annotations.\n",
      "ðŸš« Image 3375.jpg has no annotations.\n",
      "ðŸš« Image 3531.jpg has no annotations.\n",
      "ðŸš« Image 6578.jpg has no annotations.\n",
      "ðŸš« Image 1295.jpg has no annotations.\n",
      "ðŸš« Image 4065.jpg has no annotations.\n",
      "ðŸš« Image 14851.jpg has no annotations.\n",
      "ðŸš« Image 12286.jpg has no annotations.\n",
      "ðŸš« Image 19399.jpg has no annotations.\n",
      "ðŸš« Image 12412.jpg has no annotations.\n",
      "ðŸš« Image 5608.jpg has no annotations.\n",
      "ðŸš« Image 5829.jpg has no annotations.\n",
      "ðŸš« Image 3049.jpg has no annotations.\n",
      "ðŸš« Image 17755.jpg has no annotations.\n",
      "ðŸš« Image 1095.jpg has no annotations.\n",
      "ðŸš« Image 4010.jpg has no annotations.\n",
      "ðŸš« Image 2786.jpg has no annotations.\n",
      "ðŸš« Image 14145.jpg has no annotations.\n",
      "ðŸš« Image 11917.jpg has no annotations.\n",
      "ðŸš« Image 17836.jpg has no annotations.\n",
      "ðŸš« Image 15071.jpg has no annotations.\n",
      "ðŸš« Image 7671.jpg has no annotations.\n",
      "ðŸš« Image 4768.jpg has no annotations.\n",
      "ðŸš« Image 6472.jpg has no annotations.\n",
      "ðŸš« Image 387.jpg has no annotations.\n",
      "ðŸš« Image 19770.jpg has no annotations.\n",
      "ðŸš« Image 13196.jpg has no annotations.\n",
      "ðŸš« Image 12090.jpg has no annotations.\n",
      "ðŸš« Image 18500.jpg has no annotations.\n",
      "ðŸš« Image 8397.jpg has no annotations.\n",
      "ðŸš« Image 11606.jpg has no annotations.\n",
      "ðŸš« Image 8761.jpg has no annotations.\n",
      "ðŸš« Image 1627.jpg has no annotations.\n",
      "ðŸš« Image 13082.jpg has no annotations.\n",
      "ðŸš« Image 15644.jpg has no annotations.\n",
      "ðŸš« Image 7315.jpg has no annotations.\n",
      "ðŸš« Image 15821.jpg has no annotations.\n",
      "ðŸš« Image 13043.jpg has no annotations.\n",
      "ðŸš« Image 14969.jpg has no annotations.\n",
      "ðŸš« Image 17427.jpg has no annotations.\n",
      "ðŸš« Image 18390.jpg has no annotations.\n",
      "ðŸš« Image 1332.jpg has no annotations.\n",
      "ðŸš« Image 10069.jpg has no annotations.\n",
      "ðŸš« Image 270.jpg has no annotations.\n",
      "ðŸš« Image 16382.jpg has no annotations.\n",
      "ðŸš« Image 15410.jpg has no annotations.\n",
      "ðŸš« Image 5073.jpg has no annotations.\n",
      "ðŸš« Image 12874.jpg has no annotations.\n",
      "ðŸš« Image 19300.jpg has no annotations.\n",
      "ðŸš« Image 5923.jpg has no annotations.\n",
      "ðŸš« Image 7105.jpg has no annotations.\n",
      "ðŸš« Image 9420.jpg has no annotations.\n",
      "ðŸš« Image 8942.jpg has no annotations.\n",
      "ðŸš« Image 11116.jpg has no annotations.\n",
      "ðŸš« Image 238.jpg has no annotations.\n",
      "ðŸš« Image 10696.jpg has no annotations.\n",
      "ðŸš« Image 14586.jpg has no annotations.\n",
      "ðŸš« Image 16040.jpg has no annotations.\n",
      "ðŸš« Image 8822.jpg has no annotations.\n",
      "ðŸš« Image 1046.jpg has no annotations.\n",
      "ðŸš« Image 7680.jpg has no annotations.\n",
      "ðŸš« Image 19212.jpg has no annotations.\n",
      "ðŸš« Image 17538.jpg has no annotations.\n",
      "ðŸš« Image 2190.jpg has no annotations.\n",
      "ðŸš« Image 647.jpg has no annotations.\n",
      "ðŸš« Image 19609.jpg has no annotations.\n",
      "ðŸš« Image 10927.jpg has no annotations.\n",
      "ðŸš« Image 9889.jpg has no annotations.\n",
      "ðŸš« Image 14922.jpg has no annotations.\n",
      "ðŸš« Image 18344.jpg has no annotations.\n",
      "ðŸš« Image 17759.jpg has no annotations.\n",
      "ðŸš« Image 7000.jpg has no annotations.\n",
      "ðŸš« Image 11241.jpg has no annotations.\n",
      "ðŸš« Image 6397.jpg has no annotations.\n",
      "ðŸš« Image 13928.jpg has no annotations.\n",
      "ðŸš« Image 16972.jpg has no annotations.\n",
      "ðŸš« Image 11579.jpg has no annotations.\n",
      "ðŸš« Image 9411.jpg has no annotations.\n",
      "ðŸš« Image 19134.jpg has no annotations.\n",
      "ðŸš« Image 8491.jpg has no annotations.\n",
      "ðŸš« Image 8540.jpg has no annotations.\n",
      "ðŸš« Image 15210.jpg has no annotations.\n",
      "ðŸš« Image 4639.jpg has no annotations.\n",
      "ðŸš« Image 9289.jpg has no annotations.\n",
      "ðŸš« Image 17034.jpg has no annotations.\n",
      "ðŸš« Image 3930.jpg has no annotations.\n",
      "ðŸš« Image 10723.jpg has no annotations.\n",
      "ðŸš« Image 3881.jpg has no annotations.\n",
      "ðŸš« Image 17746.jpg has no annotations.\n",
      "ðŸš« Image 17015.jpg has no annotations.\n",
      "ðŸš« Image 7573.jpg has no annotations.\n",
      "ðŸš« Image 11705.jpg has no annotations.\n",
      "ðŸš« Image 8983.jpg has no annotations.\n",
      "ðŸš« Image 6142.jpg has no annotations.\n",
      "ðŸš« Image 13194.jpg has no annotations.\n",
      "ðŸš« Image 13112.jpg has no annotations.\n",
      "ðŸš« Image 17030.jpg has no annotations.\n",
      "ðŸš« Image 18768.jpg has no annotations.\n",
      "ðŸš« Image 716.jpg has no annotations.\n",
      "ðŸš« Image 5140.jpg has no annotations.\n",
      "ðŸš« Image 3078.jpg has no annotations.\n",
      "ðŸš« Image 10153.jpg has no annotations.\n",
      "ðŸš« Image 565.jpg has no annotations.\n",
      "ðŸš« Image 19534.jpg has no annotations.\n",
      "ðŸš« Image 2878.jpg has no annotations.\n",
      "ðŸš« Image 2415.jpg has no annotations.\n",
      "ðŸš« Image 17424.jpg has no annotations.\n",
      "ðŸš« Image 11137.jpg has no annotations.\n",
      "ðŸš« Image 9354.jpg has no annotations.\n",
      "ðŸš« Image 15667.jpg has no annotations.\n",
      "ðŸš« Image 17844.jpg has no annotations.\n",
      "ðŸš« Image 3795.jpg has no annotations.\n",
      "ðŸš« Image 4161.jpg has no annotations.\n",
      "ðŸš« Image 17596.jpg has no annotations.\n",
      "ðŸš« Image 18394.jpg has no annotations.\n",
      "ðŸš« Image 8165.jpg has no annotations.\n",
      "ðŸš« Image 9515.jpg has no annotations.\n",
      "ðŸš« Image 18239.jpg has no annotations.\n",
      "ðŸš« Image 4091.jpg has no annotations.\n",
      "ðŸš« Image 17671.jpg has no annotations.\n",
      "ðŸš« Image 9272.jpg has no annotations.\n",
      "ðŸš« Image 10923.jpg has no annotations.\n",
      "ðŸš« Image 18420.jpg has no annotations.\n",
      "ðŸš« Image 17512.jpg has no annotations.\n",
      "ðŸš« Image 13370.jpg has no annotations.\n",
      "ðŸš« Image 12041.jpg has no annotations.\n",
      "ðŸš« Image 8422.jpg has no annotations.\n",
      "ðŸš« Image 4628.jpg has no annotations.\n",
      "ðŸš« Image 10595.jpg has no annotations.\n",
      "ðŸš« Image 15749.jpg has no annotations.\n",
      "ðŸš« Image 13180.jpg has no annotations.\n",
      "ðŸš« Image 19015.jpg has no annotations.\n",
      "ðŸš« Image 4308.jpg has no annotations.\n",
      "ðŸš« Image 3203.jpg has no annotations.\n",
      "ðŸš« Image 9341.jpg has no annotations.\n",
      "ðŸš« Image 250.jpg has no annotations.\n",
      "ðŸš« Image 13687.jpg has no annotations.\n",
      "ðŸš« Image 19945.jpg has no annotations.\n",
      "ðŸš« Image 14366.jpg has no annotations.\n",
      "ðŸš« Image 2485.jpg has no annotations.\n",
      "ðŸš« Image 12627.jpg has no annotations.\n",
      "ðŸš« Image 6870.jpg has no annotations.\n",
      "ðŸš« Image 12098.jpg has no annotations.\n",
      "ðŸš« Image 7449.jpg has no annotations.\n",
      "ðŸš« Image 5344.jpg has no annotations.\n",
      "ðŸš« Image 8877.jpg has no annotations.\n",
      "ðŸš« Image 13475.jpg has no annotations.\n",
      "ðŸš« Image 18904.jpg has no annotations.\n",
      "ðŸš« Image 10044.jpg has no annotations.\n",
      "ðŸš« Image 19972.jpg has no annotations.\n",
      "ðŸš« Image 14519.jpg has no annotations.\n",
      "ðŸš« Image 17299.jpg has no annotations.\n",
      "ðŸš« Image 3051.jpg has no annotations.\n",
      "ðŸš« Image 15282.jpg has no annotations.\n",
      "ðŸš« Image 2422.jpg has no annotations.\n",
      "ðŸš« Image 4354.jpg has no annotations.\n",
      "ðŸš« Image 19130.jpg has no annotations.\n",
      "ðŸš« Image 2328.jpg has no annotations.\n",
      "ðŸš« Image 13798.jpg has no annotations.\n",
      "ðŸš« Image 9754.jpg has no annotations.\n",
      "ðŸš« Image 11022.jpg has no annotations.\n",
      "ðŸš« Image 17784.jpg has no annotations.\n",
      "ðŸš« Image 17179.jpg has no annotations.\n",
      "ðŸš« Image 3326.jpg has no annotations.\n",
      "ðŸš« Image 11995.jpg has no annotations.\n",
      "ðŸš« Image 3137.jpg has no annotations.\n",
      "ðŸš« Image 16725.jpg has no annotations.\n",
      "ðŸš« Image 10461.jpg has no annotations.\n",
      "ðŸš« Image 11986.jpg has no annotations.\n",
      "ðŸš« Image 9371.jpg has no annotations.\n",
      "ðŸš« Image 7987.jpg has no annotations.\n",
      "ðŸš« Image 7504.jpg has no annotations.\n",
      "ðŸš« Image 2085.jpg has no annotations.\n",
      "ðŸš« Image 15521.jpg has no annotations.\n",
      "ðŸš« Image 14555.jpg has no annotations.\n",
      "ðŸš« Image 6739.jpg has no annotations.\n",
      "ðŸš« Image 14780.jpg has no annotations.\n",
      "ðŸš« Image 881.jpg has no annotations.\n",
      "ðŸš« Image 4618.jpg has no annotations.\n",
      "ðŸš« Image 17955.jpg has no annotations.\n",
      "ðŸš« Image 2413.jpg has no annotations.\n",
      "ðŸš« Image 5186.jpg has no annotations.\n",
      "ðŸš« Image 11484.jpg has no annotations.\n",
      "ðŸš« Image 15526.jpg has no annotations.\n",
      "ðŸš« Image 12681.jpg has no annotations.\n",
      "ðŸš« Image 12751.jpg has no annotations.\n",
      "ðŸš« Image 16171.jpg has no annotations.\n",
      "ðŸš« Image 5178.jpg has no annotations.\n",
      "ðŸš« Image 19147.jpg has no annotations.\n",
      "ðŸš« Image 9318.jpg has no annotations.\n",
      "ðŸš« Image 9061.jpg has no annotations.\n",
      "ðŸš« Image 6019.jpg has no annotations.\n",
      "ðŸš« Image 11030.jpg has no annotations.\n",
      "ðŸš« Image 18222.jpg has no annotations.\n",
      "ðŸš« Image 19580.jpg has no annotations.\n",
      "ðŸš« Image 9967.jpg has no annotations.\n",
      "ðŸš« Image 4929.jpg has no annotations.\n",
      "ðŸš« Image 7710.jpg has no annotations.\n",
      "ðŸš« Image 19478.jpg has no annotations.\n",
      "ðŸš« Image 18282.jpg has no annotations.\n",
      "ðŸš« Image 3291.jpg has no annotations.\n",
      "ðŸš« Image 13703.jpg has no annotations.\n",
      "ðŸš« Image 8381.jpg has no annotations.\n",
      "ðŸš« Image 1227.jpg has no annotations.\n",
      "ðŸš« Image 6288.jpg has no annotations.\n",
      "ðŸš« Image 8488.jpg has no annotations.\n",
      "ðŸš« Image 6513.jpg has no annotations.\n",
      "ðŸš« Image 17629.jpg has no annotations.\n",
      "ðŸš« Image 848.jpg has no annotations.\n",
      "ðŸš« Image 1539.jpg has no annotations.\n",
      "ðŸš« Image 3139.jpg has no annotations.\n",
      "ðŸš« Image 12516.jpg has no annotations.\n",
      "ðŸš« Image 1888.jpg has no annotations.\n",
      "ðŸš« Image 14368.jpg has no annotations.\n",
      "ðŸš« Image 5507.jpg has no annotations.\n",
      "ðŸš« Image 9901.jpg has no annotations.\n",
      "ðŸš« Image 8535.jpg has no annotations.\n",
      "ðŸš« Image 6955.jpg has no annotations.\n",
      "ðŸš« Image 16498.jpg has no annotations.\n",
      "ðŸš« Image 11004.jpg has no annotations.\n",
      "ðŸš« Image 4939.jpg has no annotations.\n",
      "ðŸš« Image 6271.jpg has no annotations.\n",
      "ðŸš« Image 14734.jpg has no annotations.\n",
      "ðŸš« Image 2363.jpg has no annotations.\n",
      "ðŸš« Image 7166.jpg has no annotations.\n",
      "ðŸš« Image 18295.jpg has no annotations.\n",
      "ðŸš« Image 3480.jpg has no annotations.\n",
      "ðŸš« Image 18718.jpg has no annotations.\n",
      "ðŸš« Image 12931.jpg has no annotations.\n",
      "ðŸš« Image 8768.jpg has no annotations.\n",
      "ðŸš« Image 9671.jpg has no annotations.\n",
      "ðŸš« Image 12993.jpg has no annotations.\n",
      "ðŸš« Image 3524.jpg has no annotations.\n",
      "ðŸš« Image 5026.jpg has no annotations.\n",
      "ðŸš« Image 1097.jpg has no annotations.\n",
      "ðŸš« Image 9204.jpg has no annotations.\n",
      "ðŸš« Image 19994.jpg has no annotations.\n",
      "ðŸš« Image 12294.jpg has no annotations.\n",
      "ðŸš« Image 6454.jpg has no annotations.\n",
      "ðŸš« Image 1518.jpg has no annotations.\n",
      "ðŸš« Image 14772.jpg has no annotations.\n",
      "ðŸš« Image 9676.jpg has no annotations.\n",
      "ðŸš« Image 10726.jpg has no annotations.\n",
      "ðŸš« Image 4849.jpg has no annotations.\n",
      "ðŸš« Image 12307.jpg has no annotations.\n",
      "ðŸš« Image 18051.jpg has no annotations.\n",
      "ðŸš« Image 11364.jpg has no annotations.\n",
      "ðŸš« Image 1065.jpg has no annotations.\n",
      "ðŸš« Image 12943.jpg has no annotations.\n",
      "ðŸš« Image 6489.jpg has no annotations.\n",
      "ðŸš« Image 1690.jpg has no annotations.\n",
      "ðŸš« Image 162.jpg has no annotations.\n",
      "ðŸš« Image 7071.jpg has no annotations.\n",
      "ðŸš« Image 3974.jpg has no annotations.\n",
      "ðŸš« Image 235.jpg has no annotations.\n",
      "ðŸš« Image 2199.jpg has no annotations.\n",
      "ðŸš« Image 17688.jpg has no annotations.\n",
      "ðŸš« Image 17721.jpg has no annotations.\n",
      "ðŸš« Image 15814.jpg has no annotations.\n",
      "ðŸš« Image 6241.jpg has no annotations.\n",
      "ðŸš« Image 16326.jpg has no annotations.\n",
      "ðŸš« Image 7238.jpg has no annotations.\n",
      "ðŸš« Image 9919.jpg has no annotations.\n",
      "ðŸš« Image 1206.jpg has no annotations.\n",
      "ðŸš« Image 12936.jpg has no annotations.\n",
      "ðŸš« Image 16571.jpg has no annotations.\n",
      "ðŸš« Image 2091.jpg has no annotations.\n",
      "ðŸš« Image 5740.jpg has no annotations.\n",
      "ðŸš« Image 14364.jpg has no annotations.\n",
      "ðŸš« Image 8593.jpg has no annotations.\n",
      "ðŸš« Image 12574.jpg has no annotations.\n",
      "ðŸš« Image 10451.jpg has no annotations.\n",
      "ðŸš« Image 2187.jpg has no annotations.\n",
      "ðŸš« Image 10060.jpg has no annotations.\n",
      "ðŸš« Image 10245.jpg has no annotations.\n",
      "ðŸš« Image 15683.jpg has no annotations.\n",
      "ðŸš« Image 19101.jpg has no annotations.\n",
      "ðŸš« Image 19864.jpg has no annotations.\n",
      "ðŸš« Image 5008.jpg has no annotations.\n",
      "ðŸš« Image 5343.jpg has no annotations.\n",
      "ðŸš« Image 5252.jpg has no annotations.\n",
      "ðŸš« Image 1901.jpg has no annotations.\n",
      "ðŸš« Image 16343.jpg has no annotations.\n",
      "ðŸš« Image 9027.jpg has no annotations.\n",
      "ðŸš« Image 17778.jpg has no annotations.\n",
      "ðŸš« Image 18426.jpg has no annotations.\n",
      "ðŸš« Image 9664.jpg has no annotations.\n",
      "ðŸš« Image 816.jpg has no annotations.\n",
      "ðŸš« Image 15753.jpg has no annotations.\n",
      "ðŸš« Image 1260.jpg has no annotations.\n",
      "ðŸš« Image 16444.jpg has no annotations.\n",
      "ðŸš« Image 322.jpg has no annotations.\n",
      "ðŸš« Image 13186.jpg has no annotations.\n",
      "ðŸš« Image 1138.jpg has no annotations.\n",
      "ðŸš« Image 10030.jpg has no annotations.\n",
      "ðŸš« Image 3602.jpg has no annotations.\n",
      "ðŸš« Image 3190.jpg has no annotations.\n",
      "ðŸš« Image 3120.jpg has no annotations.\n",
      "ðŸš« Image 1511.jpg has no annotations.\n",
      "ðŸš« Image 2228.jpg has no annotations.\n",
      "ðŸš« Image 3115.jpg has no annotations.\n",
      "ðŸš« Image 2389.jpg has no annotations.\n",
      "ðŸš« Image 9682.jpg has no annotations.\n",
      "ðŸš« Image 7977.jpg has no annotations.\n",
      "ðŸš« Image 12595.jpg has no annotations.\n",
      "ðŸš« Image 11960.jpg has no annotations.\n",
      "ðŸš« Image 6118.jpg has no annotations.\n",
      "ðŸš« Image 3522.jpg has no annotations.\n",
      "ðŸš« Image 13489.jpg has no annotations.\n",
      "ðŸš« Image 14958.jpg has no annotations.\n",
      "ðŸš« Image 2871.jpg has no annotations.\n",
      "ðŸš« Image 15059.jpg has no annotations.\n",
      "ðŸš« Image 6004.jpg has no annotations.\n",
      "ðŸš« Image 14300.jpg has no annotations.\n",
      "ðŸš« Image 17451.jpg has no annotations.\n",
      "ðŸš« Image 6728.jpg has no annotations.\n",
      "ðŸš« Image 16774.jpg has no annotations.\n",
      "ðŸš« Image 14732.jpg has no annotations.\n",
      "ðŸš« Image 3085.jpg has no annotations.\n",
      "ðŸš« Image 9094.jpg has no annotations.\n",
      "ðŸš« Image 13419.jpg has no annotations.\n",
      "ðŸš« Image 1505.jpg has no annotations.\n",
      "ðŸš« Image 94.jpg has no annotations.\n",
      "ðŸš« Image 178.jpg has no annotations.\n",
      "ðŸš« Image 8870.jpg has no annotations.\n",
      "ðŸš« Image 12340.jpg has no annotations.\n",
      "ðŸš« Image 15412.jpg has no annotations.\n",
      "ðŸš« Image 2129.jpg has no annotations.\n",
      "ðŸš« Image 7396.jpg has no annotations.\n",
      "ðŸš« Image 8002.jpg has no annotations.\n",
      "ðŸš« Image 17235.jpg has no annotations.\n",
      "ðŸš« Image 6536.jpg has no annotations.\n",
      "ðŸš« Image 9500.jpg has no annotations.\n",
      "ðŸš« Image 11330.jpg has no annotations.\n",
      "ðŸš« Image 18157.jpg has no annotations.\n",
      "ðŸš« Image 866.jpg has no annotations.\n",
      "ðŸš« Image 1778.jpg has no annotations.\n",
      "ðŸš« Image 5208.jpg has no annotations.\n",
      "ðŸš« Image 16238.jpg has no annotations.\n",
      "ðŸš« Image 14845.jpg has no annotations.\n",
      "ðŸš« Image 9575.jpg has no annotations.\n",
      "ðŸš« Image 13386.jpg has no annotations.\n",
      "ðŸš« Image 1214.jpg has no annotations.\n",
      "ðŸš« Image 15968.jpg has no annotations.\n",
      "ðŸš« Image 1354.jpg has no annotations.\n",
      "ðŸš« Image 13050.jpg has no annotations.\n",
      "ðŸš« Image 16589.jpg has no annotations.\n",
      "ðŸš« Image 15249.jpg has no annotations.\n",
      "ðŸš« Image 6214.jpg has no annotations.\n",
      "ðŸš« Image 13907.jpg has no annotations.\n",
      "ðŸš« Image 4591.jpg has no annotations.\n",
      "ðŸš« Image 7845.jpg has no annotations.\n",
      "ðŸš« Image 16445.jpg has no annotations.\n",
      "ðŸš« Image 7255.jpg has no annotations.\n",
      "ðŸš« Image 16788.jpg has no annotations.\n",
      "ðŸš« Image 6866.jpg has no annotations.\n",
      "ðŸš« Image 7201.jpg has no annotations.\n",
      "ðŸš« Image 5427.jpg has no annotations.\n",
      "ðŸš« Image 19041.jpg has no annotations.\n",
      "ðŸš« Image 13161.jpg has no annotations.\n",
      "ðŸš« Image 7046.jpg has no annotations.\n",
      "ðŸš« Image 4912.jpg has no annotations.\n",
      "ðŸš« Image 7421.jpg has no annotations.\n",
      "ðŸš« Image 19219.jpg has no annotations.\n",
      "ðŸš« Image 2736.jpg has no annotations.\n",
      "ðŸš« Image 15723.jpg has no annotations.\n",
      "ðŸš« Image 3808.jpg has no annotations.\n",
      "ðŸš« Image 8757.jpg has no annotations.\n",
      "ðŸš« Image 14933.jpg has no annotations.\n",
      "ðŸš« Image 5557.jpg has no annotations.\n",
      "ðŸš« Image 2856.jpg has no annotations.\n",
      "ðŸš« Image 14649.jpg has no annotations.\n",
      "ðŸš« Image 14024.jpg has no annotations.\n",
      "ðŸš« Image 1608.jpg has no annotations.\n",
      "ðŸš« Image 12426.jpg has no annotations.\n",
      "ðŸš« Image 10018.jpg has no annotations.\n",
      "ðŸš« Image 17148.jpg has no annotations.\n",
      "ðŸš« Image 12850.jpg has no annotations.\n",
      "ðŸš« Image 2048.jpg has no annotations.\n",
      "ðŸš« Image 18525.jpg has no annotations.\n",
      "ðŸš« Image 2133.jpg has no annotations.\n",
      "ðŸš« Image 18223.jpg has no annotations.\n",
      "ðŸš« Image 1730.jpg has no annotations.\n",
      "ðŸš« Image 12271.jpg has no annotations.\n",
      "ðŸš« Image 11145.jpg has no annotations.\n",
      "ðŸš« Image 2933.jpg has no annotations.\n",
      "ðŸš« Image 11818.jpg has no annotations.\n",
      "ðŸš« Image 19519.jpg has no annotations.\n",
      "ðŸš« Image 6098.jpg has no annotations.\n",
      "ðŸš« Image 10047.jpg has no annotations.\n",
      "ðŸš« Image 19472.jpg has no annotations.\n",
      "ðŸš« Image 11438.jpg has no annotations.\n",
      "ðŸš« Image 15162.jpg has no annotations.\n",
      "ðŸš« Image 16338.jpg has no annotations.\n",
      "ðŸš« Image 14816.jpg has no annotations.\n",
      "ðŸš« Image 14122.jpg has no annotations.\n",
      "ðŸš« Image 14952.jpg has no annotations.\n",
      "ðŸš« Image 8132.jpg has no annotations.\n",
      "ðŸš« Image 8146.jpg has no annotations.\n",
      "ðŸš« Image 13139.jpg has no annotations.\n",
      "ðŸš« Image 15488.jpg has no annotations.\n",
      "ðŸš« Image 7698.jpg has no annotations.\n",
      "ðŸš« Image 6111.jpg has no annotations.\n",
      "ðŸš« Image 15985.jpg has no annotations.\n",
      "ðŸš« Image 15216.jpg has no annotations.\n",
      "ðŸš« Image 263.jpg has no annotations.\n",
      "ðŸš« Image 139.jpg has no annotations.\n",
      "ðŸš« Image 10859.jpg has no annotations.\n",
      "ðŸš« Image 19777.jpg has no annotations.\n",
      "ðŸš« Image 19501.jpg has no annotations.\n",
      "ðŸš« Image 4126.jpg has no annotations.\n",
      "ðŸš« Image 13716.jpg has no annotations.\n",
      "ðŸš« Image 10953.jpg has no annotations.\n",
      "ðŸš« Image 7998.jpg has no annotations.\n",
      "ðŸš« Image 19815.jpg has no annotations.\n",
      "ðŸš« Image 9085.jpg has no annotations.\n",
      "ðŸš« Image 1912.jpg has no annotations.\n",
      "ðŸš« Image 13914.jpg has no annotations.\n",
      "ðŸš« Image 5248.jpg has no annotations.\n",
      "ðŸš« Image 15817.jpg has no annotations.\n",
      "ðŸš« Image 6013.jpg has no annotations.\n",
      "ðŸš« Image 19647.jpg has no annotations.\n",
      "ðŸš« Image 6858.jpg has no annotations.\n",
      "ðŸš« Image 7794.jpg has no annotations.\n",
      "ðŸš« Image 1861.jpg has no annotations.\n",
      "ðŸš« Image 19442.jpg has no annotations.\n",
      "ðŸš« Image 12218.jpg has no annotations.\n",
      "ðŸš« Image 7022.jpg has no annotations.\n",
      "ðŸš« Image 1790.jpg has no annotations.\n",
      "ðŸš« Image 18507.jpg has no annotations.\n",
      "ðŸš« Image 4601.jpg has no annotations.\n",
      "ðŸš« Image 12054.jpg has no annotations.\n",
      "ðŸš« Image 12706.jpg has no annotations.\n",
      "ðŸš« Image 1050.jpg has no annotations.\n",
      "ðŸš« Image 2902.jpg has no annotations.\n",
      "ðŸš« Image 2335.jpg has no annotations.\n",
      "ðŸš« Image 13675.jpg has no annotations.\n",
      "ðŸš« Image 4729.jpg has no annotations.\n",
      "ðŸš« Image 12716.jpg has no annotations.\n",
      "ðŸš« Image 16624.jpg has no annotations.\n",
      "ðŸš« Image 2876.jpg has no annotations.\n",
      "ðŸš« Image 12380.jpg has no annotations.\n",
      "ðŸš« Image 8487.jpg has no annotations.\n",
      "ðŸš« Image 16132.jpg has no annotations.\n",
      "ðŸš« Image 17282.jpg has no annotations.\n",
      "ðŸš« Image 12204.jpg has no annotations.\n",
      "ðŸš« Image 6072.jpg has no annotations.\n",
      "ðŸš« Image 9412.jpg has no annotations.\n",
      "ðŸš« Image 6943.jpg has no annotations.\n",
      "ðŸš« Image 5579.jpg has no annotations.\n",
      "ðŸš« Image 13406.jpg has no annotations.\n",
      "ðŸš« Image 396.jpg has no annotations.\n",
      "ðŸš« Image 17392.jpg has no annotations.\n",
      "ðŸš« Image 12535.jpg has no annotations.\n",
      "ðŸš« Image 4099.jpg has no annotations.\n",
      "ðŸš« Image 10593.jpg has no annotations.\n",
      "ðŸš« Image 19952.jpg has no annotations.\n",
      "ðŸš« Image 422.jpg has no annotations.\n",
      "ðŸš« Image 11638.jpg has no annotations.\n",
      "ðŸš« Image 10067.jpg has no annotations.\n",
      "ðŸš« Image 3477.jpg has no annotations.\n",
      "ðŸš« Image 9601.jpg has no annotations.\n",
      "ðŸš« Image 10834.jpg has no annotations.\n",
      "ðŸš« Image 9687.jpg has no annotations.\n",
      "ðŸš« Image 8446.jpg has no annotations.\n",
      "ðŸš« Image 5282.jpg has no annotations.\n",
      "ðŸš« Image 4986.jpg has no annotations.\n",
      "ðŸš« Image 3660.jpg has no annotations.\n",
      "ðŸš« Image 17254.jpg has no annotations.\n",
      "ðŸš« Image 18666.jpg has no annotations.\n",
      "ðŸš« Image 5838.jpg has no annotations.\n",
      "ðŸš« Image 13336.jpg has no annotations.\n",
      "ðŸš« Image 13498.jpg has no annotations.\n",
      "ðŸš« Image 1866.jpg has no annotations.\n",
      "ðŸš« Image 5263.jpg has no annotations.\n",
      "ðŸš« Image 18842.jpg has no annotations.\n",
      "ðŸš« Image 16398.jpg has no annotations.\n",
      "ðŸš« Image 3519.jpg has no annotations.\n",
      "ðŸš« Image 13955.jpg has no annotations.\n",
      "ðŸš« Image 9583.jpg has no annotations.\n",
      "ðŸš« Image 18519.jpg has no annotations.\n",
      "ðŸš« Image 16818.jpg has no annotations.\n",
      "ðŸš« Image 5836.jpg has no annotations.\n",
      "ðŸš« Image 2216.jpg has no annotations.\n",
      "ðŸš« Image 3898.jpg has no annotations.\n",
      "ðŸš« Image 17089.jpg has no annotations.\n",
      "ðŸš« Image 15342.jpg has no annotations.\n",
      "ðŸš« Image 11698.jpg has no annotations.\n",
      "ðŸš« Image 18621.jpg has no annotations.\n",
      "ðŸš« Image 18501.jpg has no annotations.\n",
      "ðŸš« Image 19225.jpg has no annotations.\n",
      "ðŸš« Image 16199.jpg has no annotations.\n",
      "ðŸš« Image 13213.jpg has no annotations.\n",
      "ðŸš« Image 12771.jpg has no annotations.\n",
      "ðŸš« Image 10491.jpg has no annotations.\n",
      "ðŸš« Image 7850.jpg has no annotations.\n",
      "ðŸš« Image 19400.jpg has no annotations.\n",
      "ðŸš« Image 14796.jpg has no annotations.\n",
      "ðŸš« Image 13649.jpg has no annotations.\n",
      "ðŸš« Image 17602.jpg has no annotations.\n",
      "ðŸš« Image 8185.jpg has no annotations.\n",
      "ðŸš« Image 16564.jpg has no annotations.\n",
      "ðŸš« Image 3927.jpg has no annotations.\n",
      "ðŸš« Image 17652.jpg has no annotations.\n",
      "ðŸš« Image 16834.jpg has no annotations.\n",
      "ðŸš« Image 53.jpg has no annotations.\n",
      "ðŸš« Image 16237.jpg has no annotations.\n",
      "ðŸš« Image 6734.jpg has no annotations.\n",
      "ðŸš« Image 1006.jpg has no annotations.\n",
      "ðŸš« Image 17255.jpg has no annotations.\n",
      "ðŸš« Image 11813.jpg has no annotations.\n",
      "ðŸš« Image 10699.jpg has no annotations.\n",
      "ðŸš« Image 10802.jpg has no annotations.\n",
      "ðŸš« Image 18199.jpg has no annotations.\n",
      "ðŸš« Image 9021.jpg has no annotations.\n",
      "ðŸš« Image 8437.jpg has no annotations.\n",
      "ðŸš« Image 10397.jpg has no annotations.\n",
      "ðŸš« Image 7627.jpg has no annotations.\n",
      "ðŸš« Image 1825.jpg has no annotations.\n",
      "ðŸš« Image 18810.jpg has no annotations.\n",
      "ðŸš« Image 2488.jpg has no annotations.\n",
      "ðŸš« Image 5167.jpg has no annotations.\n",
      "ðŸš« Image 7617.jpg has no annotations.\n",
      "ðŸš« Image 17572.jpg has no annotations.\n",
      "ðŸš« Image 7913.jpg has no annotations.\n",
      "ðŸš« Image 15111.jpg has no annotations.\n",
      "ðŸš« Image 4206.jpg has no annotations.\n",
      "ðŸš« Image 14604.jpg has no annotations.\n",
      "ðŸš« Image 10172.jpg has no annotations.\n",
      "ðŸš« Image 8096.jpg has no annotations.\n",
      "ðŸš« Image 6754.jpg has no annotations.\n",
      "ðŸš« Image 10684.jpg has no annotations.\n",
      "ðŸš« Image 19182.jpg has no annotations.\n",
      "ðŸš« Image 13946.jpg has no annotations.\n",
      "ðŸš« Image 3060.jpg has no annotations.\n",
      "ðŸš« Image 259.jpg has no annotations.\n",
      "ðŸš« Image 12208.jpg has no annotations.\n",
      "ðŸš« Image 14838.jpg has no annotations.\n",
      "ðŸš« Image 413.jpg has no annotations.\n",
      "ðŸš« Image 9598.jpg has no annotations.\n",
      "ðŸš« Image 5377.jpg has no annotations.\n",
      "ðŸš« Image 18365.jpg has no annotations.\n",
      "ðŸš« Image 6001.jpg has no annotations.\n",
      "ðŸš« Image 17086.jpg has no annotations.\n",
      "ðŸš« Image 15855.jpg has no annotations.\n",
      "ðŸš« Image 13214.jpg has no annotations.\n",
      "ðŸš« Image 10157.jpg has no annotations.\n",
      "ðŸš« Image 4145.jpg has no annotations.\n",
      "ðŸš« Image 18920.jpg has no annotations.\n",
      "ðŸš« Image 111.jpg has no annotations.\n",
      "ðŸš« Image 7840.jpg has no annotations.\n",
      "ðŸš« Image 11074.jpg has no annotations.\n",
      "ðŸš« Image 12684.jpg has no annotations.\n",
      "ðŸš« Image 16685.jpg has no annotations.\n",
      "ðŸš« Image 8554.jpg has no annotations.\n",
      "ðŸš« Image 17916.jpg has no annotations.\n",
      "ðŸš« Image 11741.jpg has no annotations.\n",
      "ðŸš« Image 8008.jpg has no annotations.\n",
      "ðŸš« Image 1917.jpg has no annotations.\n",
      "ðŸš« Image 17134.jpg has no annotations.\n",
      "ðŸš« Image 10735.jpg has no annotations.\n",
      "ðŸš« Image 3500.jpg has no annotations.\n",
      "ðŸš« Image 17185.jpg has no annotations.\n",
      "ðŸš« Image 3134.jpg has no annotations.\n",
      "ðŸš« Image 11408.jpg has no annotations.\n",
      "ðŸš« Image 5527.jpg has no annotations.\n",
      "ðŸš« Image 8103.jpg has no annotations.\n",
      "ðŸš« Image 2178.jpg has no annotations.\n",
      "ðŸš« Image 11373.jpg has no annotations.\n",
      "ðŸš« Image 673.jpg has no annotations.\n",
      "ðŸš« Image 5867.jpg has no annotations.\n",
      "ðŸš« Image 5262.jpg has no annotations.\n",
      "ðŸš« Image 10009.jpg has no annotations.\n",
      "ðŸš« Image 11896.jpg has no annotations.\n",
      "ðŸš« Image 11105.jpg has no annotations.\n",
      "ðŸš« Image 8990.jpg has no annotations.\n",
      "ðŸš« Image 15273.jpg has no annotations.\n",
      "ðŸš« Image 10269.jpg has no annotations.\n",
      "ðŸš« Image 12699.jpg has no annotations.\n",
      "ðŸš« Image 17691.jpg has no annotations.\n",
      "ðŸš« Image 9056.jpg has no annotations.\n",
      "ðŸš« Image 1458.jpg has no annotations.\n",
      "ðŸš« Image 19915.jpg has no annotations.\n",
      "ðŸš« Image 1281.jpg has no annotations.\n",
      "ðŸš« Image 16610.jpg has no annotations.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "ðŸ–¼ï¸  Total images: 20000\n",
      "âœ… Images with at least one valid annotation: 19253\n",
      "ðŸš« Images with no valid annotations: 747\n",
      "âŒ Skipped annotations: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_coco_annotations(\"./json_dataset/annotations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a94c1",
   "metadata": {},
   "source": [
    "Changing the function to include negative examples of empty images (0 objects inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcd97d8-81b7-4e87-880a-cdccac70e198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from ultralytics.utils import DATASETS_DIR, LOGGER, NUM_THREADS, TQDM\n",
    "from ultralytics.utils.downloads import download, zip_directory\n",
    "from ultralytics.utils.files import increment_path\n",
    "\n",
    "\n",
    "def coco91_to_coco80_class():\n",
    "    \"\"\"\n",
    "    Converts 91-index COCO class IDs to 80-index COCO class IDs.\n",
    "\n",
    "    Returns:\n",
    "        (list): A list of 91 class IDs where the index represents the 80-index class ID and the value is the\n",
    "            corresponding 91-index class ID.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        0,\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        None,\n",
    "        11,\n",
    "        12,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        None,\n",
    "        24,\n",
    "        25,\n",
    "        None,\n",
    "        None,\n",
    "        26,\n",
    "        27,\n",
    "        28,\n",
    "        29,\n",
    "        30,\n",
    "        31,\n",
    "        32,\n",
    "        33,\n",
    "        34,\n",
    "        35,\n",
    "        36,\n",
    "        37,\n",
    "        38,\n",
    "        39,\n",
    "        None,\n",
    "        40,\n",
    "        41,\n",
    "        42,\n",
    "        43,\n",
    "        44,\n",
    "        45,\n",
    "        46,\n",
    "        47,\n",
    "        48,\n",
    "        49,\n",
    "        50,\n",
    "        51,\n",
    "        52,\n",
    "        53,\n",
    "        54,\n",
    "        55,\n",
    "        56,\n",
    "        57,\n",
    "        58,\n",
    "        59,\n",
    "        None,\n",
    "        60,\n",
    "        None,\n",
    "        None,\n",
    "        61,\n",
    "        None,\n",
    "        62,\n",
    "        63,\n",
    "        64,\n",
    "        65,\n",
    "        66,\n",
    "        67,\n",
    "        68,\n",
    "        69,\n",
    "        70,\n",
    "        71,\n",
    "        72,\n",
    "        None,\n",
    "        73,\n",
    "        74,\n",
    "        75,\n",
    "        76,\n",
    "        77,\n",
    "        78,\n",
    "        79,\n",
    "        None,\n",
    "    ]\n",
    "\n",
    "\n",
    "def coco80_to_coco91_class():\n",
    "    r\"\"\"\n",
    "    Converts 80-index (val2014) to 91-index (paper).\n",
    "    For details see https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/.\n",
    "\n",
    "    Examples:\n",
    "        >>> import numpy as np\n",
    "        >>> a = np.loadtxt(\"data/coco.names\", dtype=\"str\", delimiter=\"\\n\")\n",
    "        >>> b = np.loadtxt(\"data/coco_paper.names\", dtype=\"str\", delimiter=\"\\n\")\n",
    "\n",
    "        Convert the darknet to COCO format\n",
    "        >>> x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]\n",
    "\n",
    "        Convert the COCO to darknet format\n",
    "        >>> x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]\n",
    "    \"\"\"\n",
    "    return [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "        8,\n",
    "        9,\n",
    "        10,\n",
    "        11,\n",
    "        13,\n",
    "        14,\n",
    "        15,\n",
    "        16,\n",
    "        17,\n",
    "        18,\n",
    "        19,\n",
    "        20,\n",
    "        21,\n",
    "        22,\n",
    "        23,\n",
    "        24,\n",
    "        25,\n",
    "        27,\n",
    "        28,\n",
    "        31,\n",
    "        32,\n",
    "        33,\n",
    "        34,\n",
    "        35,\n",
    "        36,\n",
    "        37,\n",
    "        38,\n",
    "        39,\n",
    "        40,\n",
    "        41,\n",
    "        42,\n",
    "        43,\n",
    "        44,\n",
    "        46,\n",
    "        47,\n",
    "        48,\n",
    "        49,\n",
    "        50,\n",
    "        51,\n",
    "        52,\n",
    "        53,\n",
    "        54,\n",
    "        55,\n",
    "        56,\n",
    "        57,\n",
    "        58,\n",
    "        59,\n",
    "        60,\n",
    "        61,\n",
    "        62,\n",
    "        63,\n",
    "        64,\n",
    "        65,\n",
    "        67,\n",
    "        70,\n",
    "        72,\n",
    "        73,\n",
    "        74,\n",
    "        75,\n",
    "        76,\n",
    "        77,\n",
    "        78,\n",
    "        79,\n",
    "        80,\n",
    "        81,\n",
    "        82,\n",
    "        84,\n",
    "        85,\n",
    "        86,\n",
    "        87,\n",
    "        88,\n",
    "        89,\n",
    "        90,\n",
    "    ]\n",
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from ultralytics.utils import LOGGER\n",
    "from ultralytics.utils.checks import check_requirements\n",
    "from ultralytics.utils.files import increment_path\n",
    "from ultralytics.data.converter import coco91_to_coco80_class, merge_multi_segment\n",
    "from tqdm import tqdm as TQDM\n",
    "\n",
    "\n",
    "def convert_coco(\n",
    "    labels_dir=\"../coco/annotations/\",\n",
    "    save_dir=\"coco_converted/\",\n",
    "    use_segments=False,\n",
    "    use_keypoints=False,\n",
    "    cls91to80=True,\n",
    "    lvis=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts COCO dataset annotations to a YOLO annotation format suitable for training YOLO models.\n",
    "\n",
    "    Args:\n",
    "        labels_dir (str, optional): Path to directory containing COCO dataset annotation files.\n",
    "        save_dir (str, optional): Path to directory to save results to.\n",
    "        use_segments (bool, optional): Whether to include segmentation masks in the output.\n",
    "        use_keypoints (bool, optional): Whether to include keypoint annotations in the output.\n",
    "        cls91to80 (bool, optional): Whether to map 91 COCO class IDs to the corresponding 80 COCO class IDs.\n",
    "        lvis (bool, optional): Whether to convert data in LVIS dataset format.\n",
    "\n",
    "    Examples:\n",
    "        >>> convert_coco(\"../datasets/coco/annotations/\", use_segments=True, use_keypoints=False, cls91to80=False)\n",
    "        >>> convert_coco(\"../datasets/lvis/annotations/\", use_segments=True, lvis=True)\n",
    "    \"\"\"\n",
    "    # Create dataset directory\n",
    "    save_dir = increment_path(save_dir)\n",
    "    for p in save_dir / \"labels\", save_dir / \"images\":\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Convert classes\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "\n",
    "    # Process each JSON file\n",
    "    for json_file in sorted(Path(labels_dir).resolve().glob(\"*.json\")):\n",
    "        lname = \"\" if lvis else json_file.stem.replace(\"instances_\", \"\")\n",
    "        fn = Path(save_dir) / \"labels\" / lname\n",
    "        fn.mkdir(parents=True, exist_ok=True)\n",
    "        if lvis:\n",
    "            (fn / \"train2017\").mkdir(parents=True, exist_ok=True)\n",
    "            (fn / \"val2017\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(json_file, encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        images = {f\"{x['id']:d}\": x for x in data[\"images\"]}\n",
    "        annotations = defaultdict(list)\n",
    "        for ann in data[\"annotations\"]:\n",
    "            annotations[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "        image_txt = []\n",
    "\n",
    "        # Process each image, even if it has no annotations\n",
    "        for img_id, img in TQDM(images.items(), desc=f\"Images {json_file}\"):\n",
    "            anns = annotations.get(int(img_id), [])\n",
    "            h, w = img[\"height\"], img[\"width\"]\n",
    "            f = str(Path(img[\"coco_url\"]).relative_to(\"http://images.cocodataset.org\")) if lvis else img[\"file_name\"]\n",
    "            if lvis:\n",
    "                image_txt.append(str(Path(\"./images\") / f))\n",
    "\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            keypoints = []\n",
    "\n",
    "            for ann in anns:\n",
    "                if ann.get(\"iscrowd\", False):\n",
    "                    continue\n",
    "                box = np.array(ann[\"bbox\"], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # convert to center x/y\n",
    "                box[[0, 2]] /= w\n",
    "                box[[1, 3]] /= h\n",
    "                if box[2] <= 0 or box[3] <= 0:\n",
    "                    continue\n",
    "\n",
    "                cls = coco80[ann[\"category_id\"] - 1] if cls91to80 else ann[\"category_id\"]\n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                    if use_segments and ann.get(\"segmentation\") is not None:\n",
    "                        if len(ann[\"segmentation\"]) == 0:\n",
    "                            segments.append([])\n",
    "                            continue\n",
    "                        elif len(ann[\"segmentation\"]) > 1:\n",
    "                            s = merge_multi_segment(ann[\"segmentation\"])\n",
    "                            s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        else:\n",
    "                            s = [j for i in ann[\"segmentation\"] for j in i]\n",
    "                            s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                        s = [cls] + s\n",
    "                        segments.append(s)\n",
    "                    if use_keypoints and ann.get(\"keypoints\") is not None:\n",
    "                        keypoints.append(\n",
    "                            box + (np.array(ann[\"keypoints\"]).reshape(-1, 3) / np.array([w, h, 1])).reshape(-1).tolist()\n",
    "                        )\n",
    "\n",
    "            # Write label file (even if empty)\n",
    "            label_path = (fn / f).with_suffix(\".txt\")\n",
    "            with open(label_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    if use_keypoints:\n",
    "                        line = (*(keypoints[i]),)\n",
    "                    else:\n",
    "                        line = (*(segments[i] if use_segments and len(segments[i]) > 0 else bboxes[i]),)\n",
    "                    file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")\n",
    "\n",
    "        if lvis:\n",
    "            filename = Path(save_dir) / json_file.name.replace(\"lvis_v1_\", \"\").replace(\".json\", \".txt\")\n",
    "            with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.writelines(f\"{line}\\n\" for line in image_txt)\n",
    "\n",
    "    LOGGER.info(f\"{'LVIS' if lvis else 'COCO'} data converted successfully.\\nResults saved to {save_dir.resolve()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_segment_masks_to_yolo_seg(masks_dir, output_dir, classes):\n",
    "    \"\"\"\n",
    "    Converts a dataset of segmentation mask images to the YOLO segmentation format.\n",
    "\n",
    "    This function takes the directory containing the binary format mask images and converts them into YOLO segmentation format.\n",
    "    The converted masks are saved in the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        masks_dir (str): The path to the directory where all mask images (png, jpg) are stored.\n",
    "        output_dir (str): The path to the directory where the converted YOLO segmentation masks will be stored.\n",
    "        classes (int): Total classes in the dataset i.e. for COCO classes=80\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import convert_segment_masks_to_yolo_seg\n",
    "\n",
    "        The classes here is the total classes in the dataset, for COCO dataset we have 80 classes\n",
    "        >>> convert_segment_masks_to_yolo_seg(\"path/to/masks_directory\", \"path/to/output/directory\", classes=80)\n",
    "\n",
    "    Notes:\n",
    "        The expected directory structure for the masks is:\n",
    "\n",
    "            - masks\n",
    "                â”œâ”€ mask_image_01.png or mask_image_01.jpg\n",
    "                â”œâ”€ mask_image_02.png or mask_image_02.jpg\n",
    "                â”œâ”€ mask_image_03.png or mask_image_03.jpg\n",
    "                â””â”€ mask_image_04.png or mask_image_04.jpg\n",
    "\n",
    "        After execution, the labels will be organized in the following structure:\n",
    "\n",
    "            - output_dir\n",
    "                â”œâ”€ mask_yolo_01.txt\n",
    "                â”œâ”€ mask_yolo_02.txt\n",
    "                â”œâ”€ mask_yolo_03.txt\n",
    "                â””â”€ mask_yolo_04.txt\n",
    "    \"\"\"\n",
    "    pixel_to_class_mapping = {i + 1: i for i in range(classes)}\n",
    "    for mask_path in Path(masks_dir).iterdir():\n",
    "        if mask_path.suffix in {\".png\", \".jpg\"}:\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)  # Read the mask image in grayscale\n",
    "            img_height, img_width = mask.shape  # Get image dimensions\n",
    "            LOGGER.info(f\"Processing {mask_path} imgsz = {img_height} x {img_width}\")\n",
    "\n",
    "            unique_values = np.unique(mask)  # Get unique pixel values representing different classes\n",
    "            yolo_format_data = []\n",
    "\n",
    "            for value in unique_values:\n",
    "                if value == 0:\n",
    "                    continue  # Skip background\n",
    "                class_index = pixel_to_class_mapping.get(value, -1)\n",
    "                if class_index == -1:\n",
    "                    LOGGER.warning(f\"Unknown class for pixel value {value} in file {mask_path}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Create a binary mask for the current class and find contours\n",
    "                contours, _ = cv2.findContours(\n",
    "                    (mask == value).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "                )  # Find contours\n",
    "\n",
    "                for contour in contours:\n",
    "                    if len(contour) >= 3:  # YOLO requires at least 3 points for a valid segmentation\n",
    "                        contour = contour.squeeze()  # Remove single-dimensional entries\n",
    "                        yolo_format = [class_index]\n",
    "                        for point in contour:\n",
    "                            # Normalize the coordinates\n",
    "                            yolo_format.append(round(point[0] / img_width, 6))  # Rounding to 6 decimal places\n",
    "                            yolo_format.append(round(point[1] / img_height, 6))\n",
    "                        yolo_format_data.append(yolo_format)\n",
    "            # Save Ultralytics YOLO format data to file\n",
    "            output_path = Path(output_dir) / f\"{mask_path.stem}.txt\"\n",
    "            with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                for item in yolo_format_data:\n",
    "                    line = \" \".join(map(str, item))\n",
    "                    file.write(line + \"\\n\")\n",
    "            LOGGER.info(f\"Processed and stored at {output_path} imgsz = {img_height} x {img_width}\")\n",
    "\n",
    "\n",
    "def convert_dota_to_yolo_obb(dota_root_path: str):\n",
    "    \"\"\"\n",
    "    Converts DOTA dataset annotations to YOLO OBB (Oriented Bounding Box) format.\n",
    "\n",
    "    The function processes images in the 'train' and 'val' folders of the DOTA dataset. For each image, it reads the\n",
    "    associated label from the original labels directory and writes new labels in YOLO OBB format to a new directory.\n",
    "\n",
    "    Args:\n",
    "        dota_root_path (str): The root directory path of the DOTA dataset.\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import convert_dota_to_yolo_obb\n",
    "        >>> convert_dota_to_yolo_obb(\"path/to/DOTA\")\n",
    "\n",
    "    Notes:\n",
    "        The directory structure assumed for the DOTA dataset:\n",
    "\n",
    "            - DOTA\n",
    "                â”œâ”€ images\n",
    "                â”‚   â”œâ”€ train\n",
    "                â”‚   â””â”€ val\n",
    "                â””â”€ labels\n",
    "                    â”œâ”€ train_original\n",
    "                    â””â”€ val_original\n",
    "\n",
    "        After execution, the function will organize the labels into:\n",
    "\n",
    "            - DOTA\n",
    "                â””â”€ labels\n",
    "                    â”œâ”€ train\n",
    "                    â””â”€ val\n",
    "    \"\"\"\n",
    "    dota_root_path = Path(dota_root_path)\n",
    "\n",
    "    # Class names to indices mapping\n",
    "    class_mapping = {\n",
    "        \"plane\": 0,\n",
    "        \"ship\": 1,\n",
    "        \"storage-tank\": 2,\n",
    "        \"baseball-diamond\": 3,\n",
    "        \"tennis-court\": 4,\n",
    "        \"basketball-court\": 5,\n",
    "        \"ground-track-field\": 6,\n",
    "        \"harbor\": 7,\n",
    "        \"bridge\": 8,\n",
    "        \"large-vehicle\": 9,\n",
    "        \"small-vehicle\": 10,\n",
    "        \"helicopter\": 11,\n",
    "        \"roundabout\": 12,\n",
    "        \"soccer-ball-field\": 13,\n",
    "        \"swimming-pool\": 14,\n",
    "        \"container-crane\": 15,\n",
    "        \"airport\": 16,\n",
    "        \"helipad\": 17,\n",
    "    }\n",
    "\n",
    "    def convert_label(image_name, image_width, image_height, orig_label_dir, save_dir):\n",
    "        \"\"\"Converts a single image's DOTA annotation to YOLO OBB format and saves it to a specified directory.\"\"\"\n",
    "        orig_label_path = orig_label_dir / f\"{image_name}.txt\"\n",
    "        save_path = save_dir / f\"{image_name}.txt\"\n",
    "\n",
    "        with orig_label_path.open(\"r\") as f, save_path.open(\"w\") as g:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 9:\n",
    "                    continue\n",
    "                class_name = parts[8]\n",
    "                class_idx = class_mapping[class_name]\n",
    "                coords = [float(p) for p in parts[:8]]\n",
    "                normalized_coords = [\n",
    "                    coords[i] / image_width if i % 2 == 0 else coords[i] / image_height for i in range(8)\n",
    "                ]\n",
    "                formatted_coords = [f\"{coord:.6g}\" for coord in normalized_coords]\n",
    "                g.write(f\"{class_idx} {' '.join(formatted_coords)}\\n\")\n",
    "\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        image_dir = dota_root_path / \"images\" / phase\n",
    "        orig_label_dir = dota_root_path / \"labels\" / f\"{phase}_original\"\n",
    "        save_dir = dota_root_path / \"labels\" / phase\n",
    "\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        image_paths = list(image_dir.iterdir())\n",
    "        for image_path in TQDM(image_paths, desc=f\"Processing {phase} images\"):\n",
    "            if image_path.suffix != \".png\":\n",
    "                continue\n",
    "            image_name_without_ext = image_path.stem\n",
    "            img = cv2.imread(str(image_path))\n",
    "            h, w = img.shape[:2]\n",
    "            convert_label(image_name_without_ext, w, h, orig_label_dir, save_dir)\n",
    "\n",
    "\n",
    "def min_index(arr1, arr2):\n",
    "    \"\"\"\n",
    "    Find a pair of indexes with the shortest distance between two arrays of 2D points.\n",
    "\n",
    "    Args:\n",
    "        arr1 (np.ndarray): A NumPy array of shape (N, 2) representing N 2D points.\n",
    "        arr2 (np.ndarray): A NumPy array of shape (M, 2) representing M 2D points.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): A tuple containing the indexes of the points with the shortest distance in arr1 and arr2 respectively.\n",
    "    \"\"\"\n",
    "    dis = ((arr1[:, None, :] - arr2[None, :, :]) ** 2).sum(-1)\n",
    "    return np.unravel_index(np.argmin(dis, axis=None), dis.shape)\n",
    "\n",
    "\n",
    "def merge_multi_segment(segments):\n",
    "    \"\"\"\n",
    "    Merge multiple segments into one list by connecting the coordinates with the minimum distance between each segment.\n",
    "    This function connects these coordinates with a thin line to merge all segments into one.\n",
    "\n",
    "    Args:\n",
    "        segments (List[List]): Original segmentations in COCO's JSON file.\n",
    "                               Each element is a list of coordinates, like [segmentation1, segmentation2,...].\n",
    "\n",
    "    Returns:\n",
    "        s (List[np.ndarray]): A list of connected segments represented as NumPy arrays.\n",
    "    \"\"\"\n",
    "    s = []\n",
    "    segments = [np.array(i).reshape(-1, 2) for i in segments]\n",
    "    idx_list = [[] for _ in range(len(segments))]\n",
    "\n",
    "    # Record the indexes with min distance between each segment\n",
    "    for i in range(1, len(segments)):\n",
    "        idx1, idx2 = min_index(segments[i - 1], segments[i])\n",
    "        idx_list[i - 1].append(idx1)\n",
    "        idx_list[i].append(idx2)\n",
    "\n",
    "    # Use two round to connect all the segments\n",
    "    for k in range(2):\n",
    "        # Forward connection\n",
    "        if k == 0:\n",
    "            for i, idx in enumerate(idx_list):\n",
    "                # Middle segments have two indexes, reverse the index of middle segments\n",
    "                if len(idx) == 2 and idx[0] > idx[1]:\n",
    "                    idx = idx[::-1]\n",
    "                    segments[i] = segments[i][::-1, :]\n",
    "\n",
    "                segments[i] = np.roll(segments[i], -idx[0], axis=0)\n",
    "                segments[i] = np.concatenate([segments[i], segments[i][:1]])\n",
    "                # Deal with the first segment and the last one\n",
    "                if i in {0, len(idx_list) - 1}:\n",
    "                    s.append(segments[i])\n",
    "                else:\n",
    "                    idx = [0, idx[1] - idx[0]]\n",
    "                    s.append(segments[i][idx[0] : idx[1] + 1])\n",
    "\n",
    "        else:\n",
    "            for i in range(len(idx_list) - 1, -1, -1):\n",
    "                if i not in {0, len(idx_list) - 1}:\n",
    "                    idx = idx_list[i]\n",
    "                    nidx = abs(idx[1] - idx[0])\n",
    "                    s.append(segments[i][nidx:])\n",
    "    return s\n",
    "\n",
    "\n",
    "def yolo_bbox2segment(im_dir, save_dir=None, sam_model=\"sam_b.pt\", device=None):\n",
    "    \"\"\"\n",
    "    Converts existing object detection dataset (bounding boxes) to segmentation dataset or oriented bounding box (OBB)\n",
    "    in YOLO format. Generates segmentation data using SAM auto-annotator as needed.\n",
    "\n",
    "    Args:\n",
    "        im_dir (str | Path): Path to image directory to convert.\n",
    "        save_dir (str | Path): Path to save the generated labels, labels will be saved\n",
    "            into `labels-segment` in the same directory level of `im_dir` if save_dir is None.\n",
    "        sam_model (str): Segmentation model to use for intermediate segmentation data.\n",
    "        device (int | str): The specific device to run SAM models.\n",
    "\n",
    "    Notes:\n",
    "        The input directory structure assumed for dataset:\n",
    "\n",
    "            - im_dir\n",
    "                â”œâ”€ 001.jpg\n",
    "                â”œâ”€ ...\n",
    "                â””â”€ NNN.jpg\n",
    "            - labels\n",
    "                â”œâ”€ 001.txt\n",
    "                â”œâ”€ ...\n",
    "                â””â”€ NNN.txt\n",
    "    \"\"\"\n",
    "    from ultralytics import SAM\n",
    "    from ultralytics.data import YOLODataset\n",
    "    from ultralytics.utils.ops import xywh2xyxy\n",
    "\n",
    "    # NOTE: add placeholder to pass class index check\n",
    "    dataset = YOLODataset(im_dir, data=dict(names=list(range(1000))))\n",
    "    if len(dataset.labels[0][\"segments\"]) > 0:  # if it's segment data\n",
    "        LOGGER.info(\"Segmentation labels detected, no need to generate new ones!\")\n",
    "        return\n",
    "\n",
    "    LOGGER.info(\"Detection labels detected, generating segment labels by SAM model!\")\n",
    "    sam_model = SAM(sam_model)\n",
    "    for label in TQDM(dataset.labels, total=len(dataset.labels), desc=\"Generating segment labels\"):\n",
    "        h, w = label[\"shape\"]\n",
    "        boxes = label[\"bboxes\"]\n",
    "        if len(boxes) == 0:  # skip empty labels\n",
    "            continue\n",
    "        boxes[:, [0, 2]] *= w\n",
    "        boxes[:, [1, 3]] *= h\n",
    "        im = cv2.imread(label[\"im_file\"])\n",
    "        sam_results = sam_model(im, bboxes=xywh2xyxy(boxes), verbose=False, save=False, device=device)\n",
    "        label[\"segments\"] = sam_results[0].masks.xyn\n",
    "\n",
    "    save_dir = Path(save_dir) if save_dir else Path(im_dir).parent / \"labels-segment\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for label in dataset.labels:\n",
    "        texts = []\n",
    "        lb_name = Path(label[\"im_file\"]).with_suffix(\".txt\").name\n",
    "        txt_file = save_dir / lb_name\n",
    "        cls = label[\"cls\"]\n",
    "        for i, s in enumerate(label[\"segments\"]):\n",
    "            if len(s) == 0:\n",
    "                continue\n",
    "            line = (int(cls[i]), *s.reshape(-1))\n",
    "            texts.append((\"%g \" * len(line)).rstrip() % line)\n",
    "        with open(txt_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(text + \"\\n\" for text in texts)\n",
    "    LOGGER.info(f\"Generated segment labels saved in {save_dir}\")\n",
    "\n",
    "\n",
    "def create_synthetic_coco_dataset():\n",
    "    \"\"\"\n",
    "    Creates a synthetic COCO dataset with random images based on filenames from label lists.\n",
    "\n",
    "    This function downloads COCO labels, reads image filenames from label list files,\n",
    "    creates synthetic images for train2017 and val2017 subsets, and organizes\n",
    "    them in the COCO dataset structure. It uses multithreading to generate images efficiently.\n",
    "\n",
    "    Examples:\n",
    "        >>> from ultralytics.data.converter import create_synthetic_coco_dataset\n",
    "        >>> create_synthetic_coco_dataset()\n",
    "\n",
    "    Notes:\n",
    "        - Requires internet connection to download label files.\n",
    "        - Generates random RGB images of varying sizes (480x480 to 640x640 pixels).\n",
    "        - Existing test2017 directory is removed as it's not needed.\n",
    "        - Reads image filenames from train2017.txt and val2017.txt files.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_synthetic_image(image_file):\n",
    "        \"\"\"Generates synthetic images with random sizes and colors for dataset augmentation or testing purposes.\"\"\"\n",
    "        if not image_file.exists():\n",
    "            size = (random.randint(480, 640), random.randint(480, 640))\n",
    "            Image.new(\n",
    "                \"RGB\",\n",
    "                size=size,\n",
    "                color=(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)),\n",
    "            ).save(image_file)\n",
    "\n",
    "    # Download labels\n",
    "    dir = DATASETS_DIR / \"coco\"\n",
    "    url = \"https://github.com/ultralytics/assets/releases/download/v0.0.0/\"\n",
    "    label_zip = \"coco2017labels-segments.zip\"\n",
    "    download([url + label_zip], dir=dir.parent)\n",
    "\n",
    "    # Create synthetic images\n",
    "    shutil.rmtree(dir / \"labels\" / \"test2017\", ignore_errors=True)  # Remove test2017 directory as not needed\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        for subset in [\"train2017\", \"val2017\"]:\n",
    "            subset_dir = dir / \"images\" / subset\n",
    "            subset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Read image filenames from label list file\n",
    "            label_list_file = dir / f\"{subset}.txt\"\n",
    "            if label_list_file.exists():\n",
    "                with open(label_list_file, encoding=\"utf-8\") as f:\n",
    "                    image_files = [dir / line.strip() for line in f]\n",
    "\n",
    "                # Submit all tasks\n",
    "                futures = [executor.submit(create_synthetic_image, image_file) for image_file in image_files]\n",
    "                for _ in TQDM(as_completed(futures), total=len(futures), desc=f\"Generating images for {subset}\"):\n",
    "                    pass  # The actual work is done in the background\n",
    "            else:\n",
    "                LOGGER.warning(f\"Labels file {label_list_file} does not exist. Skipping image creation for {subset}.\")\n",
    "\n",
    "    LOGGER.info(\"Synthetic COCO dataset created successfully.\")\n",
    "\n",
    "\n",
    "def convert_to_multispectral(path, n_channels=10, replace=False, zip=False):\n",
    "    \"\"\"\n",
    "    Convert RGB images to multispectral images by interpolating across wavelength bands.\n",
    "\n",
    "    This function takes RGB images and interpolates them to create multispectral images with a specified number\n",
    "    of channels. It can process either a single image or a directory of images.\n",
    "\n",
    "    Args:\n",
    "        path (str | Path): Path to an image file or directory containing images to convert.\n",
    "        n_channels (int): Number of spectral channels to generate in the output image.\n",
    "        replace (bool): Whether to replace the original image file with the converted one.\n",
    "        zip (bool): Whether to zip the converted images into a zip file.\n",
    "\n",
    "    Examples:\n",
    "        >>> # Convert a single image\n",
    "        >>> convert_to_multispectral(\"path/to/image.jpg\", n_channels=10)\n",
    "        >>> # Convert a dataset\n",
    "        >>> convert_to_multispectral(\"../datasets/coco8\", n_channels=10)\n",
    "    \"\"\"\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    from ultralytics.data.utils import IMG_FORMATS\n",
    "\n",
    "    path = Path(path)\n",
    "    if path.is_dir():\n",
    "        # Process directory\n",
    "        im_files = sum([list(path.rglob(f\"*.{ext}\")) for ext in (IMG_FORMATS - {\"tif\", \"tiff\"})], [])\n",
    "        for im_path in im_files:\n",
    "            try:\n",
    "                convert_to_multispectral(im_path, n_channels)\n",
    "                if replace:\n",
    "                    im_path.unlink()\n",
    "            except Exception as e:\n",
    "                LOGGER.info(f\"Error converting {im_path}: {e}\")\n",
    "\n",
    "        if zip:\n",
    "            zip_directory(path)\n",
    "    else:\n",
    "        # Process a single image\n",
    "        output_path = path.with_suffix(\".tiff\")\n",
    "        img = cv2.cvtColor(cv2.imread(str(path)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Interpolate all pixels at once\n",
    "        rgb_wavelengths = np.array([650, 510, 475])  # R, G, B wavelengths (nm)\n",
    "        target_wavelengths = np.linspace(450, 700, n_channels)\n",
    "        f = interp1d(rgb_wavelengths.T, img, kind=\"linear\", bounds_error=False, fill_value=\"extrapolate\")\n",
    "        multispectral = f(target_wavelengths)\n",
    "        cv2.imwritemulti(str(output_path), np.clip(multispectral, 0, 255).astype(np.uint8).transpose(2, 0, 1))\n",
    "        LOGGER.info(f\"Converted {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e413b857-dd77-4b60-8a44-06348451d6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images /home/jupyter/til25-import-torch/cv/json_dataset/annotations.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:02<00:00, 6765.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /home/jupyter/til25-import-torch/cv/yaml_dataset2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_coco(\n",
    "    labels_dir=\"/home/jupyter/til25-import-torch/cv/json_dataset\",  # Directory containing your json file\n",
    "    save_dir=\"/home/jupyter/til25-import-torch/cv/yaml_dataset\",\n",
    "    use_keypoints=False,  # Since you're using keypoints data\n",
    "    use_segments=False,\n",
    "    cls91to80=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6a957c-e2ec-4997-bffb-cc26e229f560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified split complete: 15999 train, 4001 val\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Paths\n",
    "images_src = Path(\"/home/jupyter/til25-import-torch/cv/shrinked_dataset/images\")\n",
    "labels_src = Path(\"/home/jupyter/til25-import-torch/cv/shrinked_dataset/labels/\")\n",
    "dst_base = Path(\"/home/jupyter/til25-import-torch/cv/aug_dataset_split\")\n",
    "\n",
    "# Make sure output folders exist\n",
    "for split in ['train/images', 'train/labels', 'val/images', 'val/labels']:\n",
    "    (dst_base / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Gather image files and determine dominant class for stratification\n",
    "image_paths = list(images_src.glob(\"*.jpg\")) + list(images_src.glob(\"*.png\")) + list(images_src.glob(\"*.jpeg\"))\n",
    "\n",
    "labeled_image_names = []\n",
    "labeled_class_labels = []\n",
    "unlabeled_image_names = []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    label_file = labels_src / (img_path.stem + \".txt\")\n",
    "    if not label_file.exists():\n",
    "        continue  # skip images without any label file\n",
    "\n",
    "    try:\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "        if not lines:\n",
    "            # Empty label file, treat as unlabeled image\n",
    "            unlabeled_image_names.append(img_path.name)\n",
    "        else:\n",
    "            class_ids = [int(line.split()[0]) for line in lines]\n",
    "            dominant_class = Counter(class_ids).most_common(1)[0][0]\n",
    "            labeled_image_names.append(img_path.name)\n",
    "            labeled_class_labels.append(dominant_class)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {label_file}: {e}\")\n",
    "\n",
    "# Stratified split for labeled images\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(splitter.split(labeled_image_names, labeled_class_labels))\n",
    "\n",
    "train_images = [labeled_image_names[i] for i in train_idx]\n",
    "val_images = [labeled_image_names[i] for i in val_idx]\n",
    "\n",
    "# Random split for unlabeled images\n",
    "random.seed(42)\n",
    "random.shuffle(unlabeled_image_names)\n",
    "split_point = int(0.8 * len(unlabeled_image_names))\n",
    "train_images += unlabeled_image_names[:split_point]\n",
    "val_images += unlabeled_image_names[split_point:]\n",
    "\n",
    "# Helper to symlink image + label\n",
    "def symlink_subset(image_list, split):\n",
    "    for img_name in image_list:\n",
    "        label_name = img_name.rsplit('.', 1)[0] + \".txt\"\n",
    "\n",
    "        img_src = images_src / img_name\n",
    "        lbl_src = labels_src / label_name\n",
    "\n",
    "        img_dst = dst_base / split / \"images\" / img_name\n",
    "        lbl_dst = dst_base / split / \"labels\" / label_name\n",
    "\n",
    "        try:\n",
    "            os.symlink(img_src.resolve(), img_dst)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "\n",
    "        # Symlink label file even if empty\n",
    "        if lbl_src.exists():\n",
    "            try:\n",
    "                os.symlink(lbl_src.resolve(), lbl_dst)\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "\n",
    "# Create symlinks for train and val sets\n",
    "symlink_subset(train_images, \"train\")\n",
    "symlink_subset(val_images, \"val\")\n",
    "\n",
    "print(f\"Stratified split complete: {len(train_images)} train, {len(val_images)} val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef14965-e2bf-4c40-b25d-160256e59556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cvenv",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "CVenv",
   "language": "python",
   "name": "cvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
